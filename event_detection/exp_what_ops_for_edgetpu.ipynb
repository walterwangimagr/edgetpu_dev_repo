{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, MaxPool2D, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "import re\n",
    "import os \n",
    "import glob \n",
    "import random\n",
    "import logging\n",
    "from tensorflow.keras import backend as K\n",
    "import math\n",
    "import cv2\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_channels(bayer):\n",
    "    r, g, b = tf.zeros_like(bayer), tf.zeros_like(bayer), tf.zeros_like(bayer)\n",
    "    r[::2, ::2] = bayer[::2, ::2]  # Red channel\n",
    "    g[1::2, ::2] = bayer[1::2, ::2]  # Green channel for even rows\n",
    "    g[::2, 1::2] = bayer[::2, 1::2]  # Green channel for odd rows\n",
    "    g[1::2, 1::2] = bayer[1::2, 1::2]  # Blue channel\n",
    "    return r, g, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# red channel \n",
    "    pad_r = np.pad(r, (1,1), mode='constant')\n",
    "    pad_r[1:-1:2, 2:-1:2] = (pad_r[1:-1:2, 1:-1:2] + pad_r[1:-1:2, 3::2]) / 2\n",
    "    pad_r[2:-1:2, 1:-1:2] = (pad_r[1:-1:2, 1:-1:2] + pad_r[3::2, 1:-1:2]) / 2\n",
    "    pad_r[2:-1:2, 2:-1:2] = (pad_r[1:-1:2, 1:-1:2] + pad_r[3::2, 1:-1:2] + pad_r[1:-1:2, 3::2] + pad_r[3::2, 3::2]) / 4\n",
    "    new_r = pad_r[1:-1, 1:-1]\n",
    "    # green channel \n",
    "    pad_g = np.pad(g, (1,1), mode='constant')\n",
    "    pad_g[1:-1:2, 1:-1:2] = (pad_g[0:-2:2, 1:-1:2] + pad_g[1:-1:2, 0:-2:2] + pad_g[1:-1:2, 2::2] + pad_g[2::2, 1:-1:2]) / 4\n",
    "    pad_g[2::2, 2::2] = (pad_g[2::2, 1:-2:2] + pad_g[1:-1:2, 2::2] + pad_g[2::2, 3::2] + pad_g[3::2, 2::2]) / 4\n",
    "    new_g = pad_g[1:-1, 1:-1]\n",
    "    # blue channel \n",
    "    pad_b = np.pad(b, (1,1), mode='constant')\n",
    "    pad_b[1:-1:2, 2:-1:2] = (pad_b[0:-2:2, 2:-1:2] + pad_b[2::2, 2::2]) / 2\n",
    "    pad_b[2:-1:2, 1:-1:2] = (pad_b[2::2, 0:-2:2] + pad_b[2::2, 2::2]) / 2\n",
    "    pad_b[1:-1:2, 1:-1:2] = (pad_b[0:-2:2, 0:-2:2] + pad_b[0:-2:2, 2:-1:2] + pad_b[2:-1:2, 0:-2:2] + pad_b[2::2, 2::2]) / 4\n",
    "    new_b = pad_b[1:-1, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "workable tf ops\n",
    "tf.concact([r,g,b], axis=-1) work like stack \n",
    "tf.zeros(shape)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debayer(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Debayer, self).__init__()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net(input_shape=(324,324,1)):\n",
    "    # (None, 324, 324, 1)\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = Debayer()(inputs)\n",
    "    model = Model(inputs, x, name=\"demosaic\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    dataset_dir = \"/app/event_detection/data/train/something\"\n",
    "    files = glob.glob(dataset_dir + \"/*.bayer\")\n",
    "    for file in files:\n",
    "        img = tf.io.read_file(file)\n",
    "        img = tf.io.decode_raw(img, tf.uint8)\n",
    "        img = tf.cast(img, tf.float32) / 255.\n",
    "        img_shape = [324, 324, 1]\n",
    "        img = tf.reshape(img, img_shape)\n",
    "        img = tf.expand_dims(img, axis=0)\n",
    "        yield [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 324, 324, 1)\n",
      "(None, 162, 162, 1)\n",
      "(1, 162, 162, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    <ipython-input-257-530341d656c7>:12 call  *\n        r_np[..., ::2, ::2, :] = inputs[..., ::2, ::2, :]\n\n    TypeError: __array__() takes 1 positional argument but 2 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-eed9b8117c63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-258-ef8759bf7769>\u001b[0m in \u001b[0;36mbuild_net\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# (None, 324, 324, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDebayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"demosaic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-257-530341d656c7>:12 call  *\n        r_np[..., ::2, ::2, :] = inputs[..., ::2, ::2, :]\n\n    TypeError: __array__() takes 1 positional argument but 2 were given\n"
     ]
    }
   ],
   "source": [
    "model = build_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 324, 324)\n"
     ]
    }
   ],
   "source": [
    "rggb_tile = np.array([[1, 2], [3, 4]], dtype=np.float32)\n",
    "repeats = (162, 162)\n",
    "rggb_tiles = np.tile(rggb_tile, repeats)\n",
    "inputs = tf.cast(rggb_tiles, tf.float32)\n",
    "inputs = tf.expand_dims(tf.expand_dims(inputs, axis=-1), axis=0)\n",
    "output = model(inputs)\n",
    "print(output.shape)\n",
    "# print(np.squeeze(output.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ConverterError",
     "evalue": "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1024:0: error: 'tf.StridedSlice' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201:0: note: called from\n<ipython-input-233-3b7c4a90aa88>:7:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:302:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py:134:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:600:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1024:0: note: see current operation: %0 = \"tf.StridedSlice\"(%arg0, %cst_0, %cst_1, %cst_2) {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64} : (tensor<?x324x324x1xf32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?x324x324xf32>\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\n\ttf.StridedSlice {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64}\n<unknown>:0: note: see current operation: \"func\"() ( {\n^bb0(%arg0: tensor<?x324x324x1xf32>):  // no predecessors\n  %cst = \"std.constant\"() {value = dense<5.000000e+00> : tensor<f32>} : () -> tensor<f32>\n  %cst_0 = \"std.constant\"() {value = dense<0> : tensor<2xi32>} : () -> tensor<2xi32>\n  %cst_1 = \"std.constant\"() {value = dense<[0, 1]> : tensor<2xi32>} : () -> tensor<2xi32>\n  %cst_2 = \"std.constant\"() {value = dense<1> : tensor<2xi32>} : () -> tensor<2xi32>\n  %0 = \"tf.StridedSlice\"(%arg0, %cst_0, %cst_1, %cst_2) {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64} : (tensor<?x324x324x1xf32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?x324x324xf32>\n  %1 = \"tfl.add\"(%0, %cst) {fused_activation_function = \"NONE\"} : (tensor<?x324x324xf32>, tensor<f32>) -> tensor<?x324x324xf32>\n  \"std.return\"(%1) : (tensor<?x324x324xf32>) -> ()\n}) {sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"input_48\", outputs = \"Identity\"}, type = (tensor<?x324x324x1xf32>) -> tensor<?x324x324xf32>} : () -> ()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    198\u001b[0m                                                  \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                                                  enable_mlir_converter)\n\u001b[0m\u001b[1;32m    200\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/wrap_toco.py\u001b[0m in \u001b[0;36mwrapped_toco_convert\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m       enable_mlir_converter)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1024:0: error: 'tf.StridedSlice' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201:0: note: called from\n<ipython-input-233-3b7c4a90aa88>:7:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:302:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py:134:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:600:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1024:0: note: see current operation: %0 = \"tf.StridedSlice\"(%arg0, %cst_0, %cst_1, %cst_2) {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64} : (tensor<?x324x324x1xf32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?x324x324xf32>\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\n\ttf.StridedSlice {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64}\n<unknown>:0: note: see current operation: \"func\"() ( {\n^bb0(%arg0: tensor<?x324x324x1xf32>):  // no predecessors\n  %cst = \"std.constant\"() {value = dense<5.000000e+00> : tensor<f32>} : () -> tensor<f32>\n  %cst_0 = \"std.constant\"() {value = dense<0> : tensor<2xi32>} : () -> tensor<2xi32>\n  %cst_1 = \"std.constant\"() {value = dense<[0, 1]> : tensor<2xi32>} : () -> tensor<2xi32>\n  %cst_2 = \"std.constant\"() {value = dense<1> : tensor<2xi32>} : () -> tensor<2xi32>\n  %0 = \"tf.StridedSlice\"(%arg0, %cst_0, %cst_1, %cst_2) {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64} : (tensor<?x324x324x1xf32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?x324x324xf32>\n  %1 = \"tfl.add\"(%0, %cst) {fused_activation_function = \"NONE\"} : (tensor<?x324x324xf32>, tensor<f32>) -> tensor<?x324x324xf32>\n  \"std.return\"(%1) : (tensor<?x324x324xf32>) -> ()\n}) {sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"input_48\", outputs = \"Identity\"}, type = (tensor<?x324x324x1xf32>) -> tensor<?x324x324xf32>} : () -> ()\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-b0a737b6f0b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_input_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_output_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/app/event_detection/model.tflite\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     return super(TFLiteKerasModelConverterV2,\n\u001b[0;32m--> 831\u001b[0;31m                  self).convert(graph_def, input_tensors, output_tensors)\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         **converter_kwargs)\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     calibrate_and_quantize, flags = quant_mode.quantizer_flags(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_executable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_toco_from_proto_bin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConverterError\u001b[0m: /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1024:0: error: 'tf.StridedSlice' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201:0: note: called from\n<ipython-input-233-3b7c4a90aa88>:7:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:302:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py:134:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:600:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1024:0: note: see current operation: %0 = \"tf.StridedSlice\"(%arg0, %cst_0, %cst_1, %cst_2) {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64} : (tensor<?x324x324x1xf32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?x324x324xf32>\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\n\ttf.StridedSlice {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64}\n<unknown>:0: note: see current operation: \"func\"() ( {\n^bb0(%arg0: tensor<?x324x324x1xf32>):  // no predecessors\n  %cst = \"std.constant\"() {value = dense<5.000000e+00> : tensor<f32>} : () -> tensor<f32>\n  %cst_0 = \"std.constant\"() {value = dense<0> : tensor<2xi32>} : () -> tensor<2xi32>\n  %cst_1 = \"std.constant\"() {value = dense<[0, 1]> : tensor<2xi32>} : () -> tensor<2xi32>\n  %cst_2 = \"std.constant\"() {value = dense<1> : tensor<2xi32>} : () -> tensor<2xi32>\n  %0 = \"tf.StridedSlice\"(%arg0, %cst_0, %cst_1, %cst_2) {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64} : (tensor<?x324x324x1xf32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?x324x324xf32>\n  %1 = \"tfl.add\"(%0, %cst) {fused_activation_function = \"NONE\"} : (tensor<?x324x324xf32>, tensor<f32>) -> tensor<?x324x324xf32>\n  \"std.return\"(%1) : (tensor<?x324x324xf32>) -> ()\n}) {sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"input_48\", outputs = \"Identity\"}, type = (tensor<?x324x324x1xf32>) -> tensor<?x324x324xf32>} : () -> ()\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "save_path = \"/app/event_detection/model.tflite\"\n",
    "\n",
    "with open(save_path, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge TPU Compiler version 16.0.384591198\n",
      "Started a compilation timeout timer of 180 seconds.\n",
      "\n",
      "Model compiled successfully in 17 ms.\n",
      "\n",
      "Input model: model.tflite\n",
      "Input size: 10.95MiB\n",
      "Output model: model_edgetpu.tflite\n",
      "Output size: 168.00B\n",
      "On-chip memory used for caching model parameters: 0.00B\n",
      "On-chip memory remaining for caching model parameters: 0.00B\n",
      "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
      "Number of Edge TPU subgraphs: 0\n",
      "Total number of operations: 0\n",
      "Operation log: model_edgetpu.log\n",
      "See the operation log file for individual operation details.\n",
      "Compilation child process completed within timeout period.\n",
      "Compilation succeeded! \n"
     ]
    }
   ],
   "source": [
    "!edgetpu_compiler model.tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycoral.utils import edgetpu\n",
    "from pycoral.adapters import common\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import os \n",
    "import re\n",
    "import glob \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(original, augmented, figure_size=(10,5)):\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Original image')\n",
    "    plt.imshow(original)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Augmented image')\n",
    "    plt.imshow(augmented)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_bayer(bayer_path, img_w=324, img_h=324):\n",
    "    bayer = tf.io.read_file(bayer_path)\n",
    "    bayer = tf.io.decode_raw(bayer, tf.uint8)\n",
    "    bayer = tf.cast(bayer, tf.float32) / 255.\n",
    "    bayer_shape = [324, 324, 1]\n",
    "    bayer = tf.reshape(bayer, bayer_shape)\n",
    "    bayer = tf.expand_dims(bayer, axis=0)\n",
    "    return bayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantized_input(input_tensor, input_scale, input_zero_point):\n",
    "    return tf.cast((input_tensor / input_scale + input_zero_point), tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantized_output(output_tensor, output_scale, output_zero_point):\n",
    "    return tf.cast(((output_tensor - output_zero_point) * output_scale), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/app/event_detection/model_edgetpu.tflite\"\n",
    "interpreter = edgetpu.make_interpreter(model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "input_scale, input_zero_point = input_details[0]['quantization']\n",
    "output_scale, output_zero_point = output_details[0]['quantization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 324, 324, 1)\n"
     ]
    }
   ],
   "source": [
    "bayer_path = \"/app/event_detection/data/train/something/1690946037374_3689508_0_3e08da56-2b83-f591-35f5-10e7c21b3d5f.bayer\"\n",
    "bayer = prepare_input_bayer(bayer_path)\n",
    "print(bayer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 324, 324, 1)\n"
     ]
    }
   ],
   "source": [
    "input_data = quantized_input(bayer, input_scale, input_zero_point)\n",
    "print(input_data.shape)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "deq_output = dequantized_output(output_data, output_scale, output_zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 324, 324, 8])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deq_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
