{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Conv2D, BatchNormalization, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(object):\n",
    "    def __call__(self, x):\n",
    "        return x * tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "\n",
    "class Swish(object):\n",
    "    def __call__(self, x):\n",
    "        return tf.nn.swish(x)  # tf.nn.leaky_relu(x, alpha=0.1)\n",
    "\n",
    "\n",
    "class Conv(Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, padding='SAME', groups=1):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = Conv2D(filters, kernel_size, strides, padding, groups=groups, use_bias=False,\n",
    "                           kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                           kernel_regularizer=tf.keras.regularizers.L2(5e-4))\n",
    "        self.bn = BatchNormalization()\n",
    "        self.activation = Mish()\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.activation(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class DWConv(Layer):\n",
    "    def __init__(self, filters, kernel_size, strides):\n",
    "        super(DWConv, self).__init__()\n",
    "        self.conv = Conv(filters, kernel_size, strides, groups=1)  # Todo\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Focus(Layer):\n",
    "    def __init__(self, filters, kernel_size, strides=1, padding='SAME'):\n",
    "        super(Focus, self).__init__()\n",
    "        self.conv = Conv(filters, kernel_size, strides, padding)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.conv(tf.concat([x[..., ::2, ::2, :],\n",
    "                                    x[..., 1::2, ::2, :],\n",
    "                                    x[..., ::2, 1::2, :],\n",
    "                                    x[..., 1::2, 1::2, :]],\n",
    "                                   axis=-1))\n",
    "\n",
    "\n",
    "class CrossConv(Layer):\n",
    "    def __init__(self, filters, kernel_size, strides=1, groups=1, expansion=1, shortcut=False):\n",
    "        super(CrossConv, self).__init__()\n",
    "        units_e = int(filters * expansion)\n",
    "        self.conv1 = Conv(units_e, (1, kernel_size), (1, strides))\n",
    "        self.conv2 = Conv(filters, (kernel_size, 1), (strides, 1), groups=groups)\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.shortcut:\n",
    "            return x + self.conv2(self.conv1(x))\n",
    "        return self.conv2(self.conv1(x))\n",
    "\n",
    "\n",
    "class MP(Layer):\n",
    "    # Spatial pyramid pooling layer\n",
    "    def __init__(self, k=2):\n",
    "        super(MP, self).__init__()\n",
    "        self.m = MaxPool2D(pool_size=k, strides=k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.m(x)\n",
    "\n",
    "\n",
    "class Bottleneck(Layer):\n",
    "    def __init__(self, units, shortcut=True, expansion=0.5):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = Conv(int(units * expansion), 1, 1)\n",
    "        self.conv2 = Conv(units, 3, 1)\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.shortcut:\n",
    "            return x + self.conv2(self.conv1(x))\n",
    "        return self.conv2(self.conv1(x))\n",
    "\n",
    "\n",
    "class BottleneckCSP(Layer):\n",
    "    def __init__(self, units, n_layer=1, shortcut=True, expansion=0.5):\n",
    "        super(BottleneckCSP, self).__init__()\n",
    "        units_e = int(units * expansion)\n",
    "        self.conv1 = Conv(units_e, 1, 1)\n",
    "        self.conv2 = Conv2D(units_e, 1, 1, use_bias=False, kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        self.conv3 = Conv2D(units_e, 1, 1, use_bias=False, kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        self.conv4 = Conv(units, 1, 1)\n",
    "        self.bn = BatchNormalization(momentum=0.03)\n",
    "        self.activation = Mish()\n",
    "        self.modules = tf.keras.Sequential([Bottleneck(units_e, shortcut, expansion=1.0) for _ in range(n_layer)])\n",
    "\n",
    "    def call(self, x):\n",
    "        y1 = self.conv3(self.modules(self.conv1(x)))\n",
    "        y2 = self.conv2(x)\n",
    "        return self.conv4(self.activation(self.bn(tf.concat([y1, y2], axis=-1))))\n",
    "\n",
    "\n",
    "class BottleneckCSP2(Layer):\n",
    "    def __init__(self, units, n_layer=1, shortcut=False, expansion=0.5):\n",
    "        super(BottleneckCSP2, self).__init__()\n",
    "        units_e = int(units)  # hidden channels\n",
    "        self.conv1 = Conv(units_e, 1, 1)\n",
    "        self.conv2 = Conv2D(units_e, 1, 1, use_bias=False, kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        self.conv3 = Conv(units, 1, 1)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.activation = Mish()\n",
    "        self.modules = tf.keras.Sequential([Bottleneck(units_e, shortcut, expansion=1.0) for _ in range(n_layer)])\n",
    "\n",
    "    def call(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        y1 = self.modules(x1)\n",
    "        y2 = self.conv2(x1)\n",
    "        return self.conv3(self.activation(self.bn(tf.concat([y1, y2], axis=-1))))\n",
    "\n",
    "\n",
    "class VoVCSP(Layer):\n",
    "    def __init__(self, units, expansion=0.5):\n",
    "        super(VoVCSP, self).__init__()\n",
    "        units_e = int(units * expansion)\n",
    "        self.conv1 = Conv(units_e // 2, 3, 1)\n",
    "        self.conv2 = Conv(units_e // 2, 3, 1)\n",
    "        self.conv3 = Conv(units_e, 1, 1)\n",
    "\n",
    "    def call(self, x):\n",
    "        _, x1 = tf.split(x, 2, axis=1)\n",
    "        x1 = self.conv1(x1)\n",
    "        x2 = self.conv2(x1)\n",
    "        return self.conv3(tf.concat([x1, x2], axis=-1))\n",
    "\n",
    "\n",
    "class SPP(Layer):\n",
    "    def __init__(self, units, kernels=(5, 9, 13)):\n",
    "        super(SPP, self).__init__()\n",
    "        units_e = units // 2  # Todo:\n",
    "        self.conv1 = Conv(units_e, 1, 1)\n",
    "        self.conv2 = Conv(units, 1, 1)\n",
    "        self.modules = [MaxPool2D(pool_size=x, strides=1, padding='SAME') for x in kernels]  # Todo: padding check\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return self.conv2(tf.concat([x] + [module(x) for module in self.modules], axis=-1))\n",
    "\n",
    "\n",
    "class SPPCSP(Layer):\n",
    "    # Cross Stage Partial Networks\n",
    "    def __init__(self, units, n=1, shortcut=False, expansion=0.5, kernels=(5, 9, 13)):\n",
    "        super(SPPCSP, self).__init__()\n",
    "        units_e = int(2 * units * expansion)\n",
    "        self.conv1 = Conv(units_e, 1, 1)\n",
    "        self.conv2 = Conv2D(units_e, 1, 1, use_bias=False, kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        self.conv3 = Conv(units_e, 3, 1)\n",
    "        self.conv4 = Conv(units_e, 1, 1)\n",
    "        self.modules = [MaxPool2D(pool_size=x, strides=1, padding='same') for x in kernels]\n",
    "        self.conv5 = Conv(units_e, 1, 1)\n",
    "        self.conv6 = Conv(units_e, 3, 1)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.act = Mish()\n",
    "        self.conv7 = Conv(units, 1, 1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x1 = self.conv4(self.conv3(self.conv1(x)))\n",
    "        y1 = self.conv6(self.conv5(tf.concat([x1] + [module(x1) for module in self.modules], axis=-1)))\n",
    "        y2 = self.conv2(x)\n",
    "        return self.conv7(self.act(self.bn(tf.concat([y1, y2], axis=-1))))\n",
    "\n",
    "\n",
    "class Upsample(Layer):\n",
    "    def __init__(self, i=None, ratio=2, method='bilinear'):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.ratio = ratio\n",
    "        self.method = method\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.image.resize(x, (tf.shape(x)[1] * self.ratio, tf.shape(x)[2] * self.ratio), method=self.method)\n",
    "\n",
    "\n",
    "class Concat(Layer):\n",
    "    def __init__(self, dims=-1):\n",
    "        super(Concat, self).__init__()\n",
    "        self.dims = dims\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.concat(x, self.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect(Layer):\n",
    "    def __init__(self, num_classes, anchors=()):\n",
    "        super(Detect, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_scale = len(anchors)\n",
    "        self.output_dims = self.num_classes + 5\n",
    "        self.num_anchors = len(anchors[0])//2\n",
    "        self.stride = np.array([8, 16, 32], np.float32)  # fixed here, modify if structure changes\n",
    "        self.anchors = tf.cast(tf.reshape(anchors, [self.num_anchors, -1, 2]), tf.float32)\n",
    "        self.modules = [Conv2D(self.output_dims * self.num_anchors, 1, use_bias=False) for _ in range(self.num_scale)]\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        res = []       \n",
    "        for i in range(self.num_scale):  # number of scale layer, default=3\n",
    "            y = self.modules[i](x[i])\n",
    "            _, grid1, grid2, _ = y.shape\n",
    "            y = tf.reshape(y, (-1, grid1, grid2, self.num_scale, self.output_dims))               \n",
    "          \n",
    "            grid_xy = tf.meshgrid(tf.range(grid1), tf.range(grid2))  # grid[x][y]==(y,x)\n",
    "            grid_xy = tf.cast(tf.expand_dims(tf.stack(grid_xy, axis=-1), axis=2),tf.float32)  \n",
    "\n",
    "            y_norm = tf.sigmoid(y)  # sigmoid for all dims\n",
    "            xy, wh, conf, classes = tf.split(y_norm, (2, 2, 1, self.num_classes), axis=-1)\n",
    "\n",
    "            pred_xy = (xy * 2. - 0.5 + grid_xy) * self.stride[i]  # decode pred to xywh\n",
    "            pred_wh = (wh * 2) ** 2 * self.anchors[i] * self.stride[i]\n",
    "            \n",
    "            out = tf.concat([pred_xy, pred_wh, conf, classes], axis=-1)\n",
    "            res.append(out)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo(object):\n",
    "    def __init__(self, yaml_dir):\n",
    "        with open(yaml_dir) as f:\n",
    "            yaml_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        self.module_list = self.parse_model(yaml_dict)\n",
    "        module = self.module_list[-1]\n",
    "        if isinstance(module, Detect):\n",
    "            # transfer the anchors to grid coordinator, 3 * 3 * 2\n",
    "            module.anchors /= tf.reshape(module.stride, [-1, 1, 1])\n",
    "\n",
    "    def __call__(self, img_size, name='yolo'):\n",
    "        x = tf.keras.Input([img_size, img_size, 3])\n",
    "        output = self.forward(x)\n",
    "        return tf.keras.Model(inputs=x, outputs=output, name=name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        for module in self.module_list:\n",
    "            if module.f != -1:  # if not from previous layer\n",
    "                if isinstance(module.f, int):\n",
    "                    x = y[module.f]\n",
    "                else:\n",
    "                    x = [x if j == -1 else y[j] for j in module.f]\n",
    "\n",
    "            x = module(x)\n",
    "            y.append(x)\n",
    "        return x\n",
    "\n",
    "    def parse_model(self, yaml_dict):\n",
    "        anchors, nc = yaml_dict['anchors'], yaml_dict['nc']\n",
    "        depth_multiple, width_multiple = yaml_dict['depth_multiple'], yaml_dict['width_multiple']\n",
    "        num_anchors = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors\n",
    "        output_dims = num_anchors * (nc + 5)\n",
    "\n",
    "        layers = []\n",
    "        # from, number, module, args\n",
    "        for i, (f, number, module, args) in enumerate(yaml_dict['backbone'] + yaml_dict['head']):\n",
    "            # all component is a Class, initialize here, call in self.forward\n",
    "            module = eval(module) if isinstance(module, str) else module\n",
    "\n",
    "            for j, arg in enumerate(args):\n",
    "                try:\n",
    "                    args[j] = eval(arg) if isinstance(arg, str) else arg  # eval strings, like Detect(nc, anchors)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            number = max(round(number * depth_multiple), 1) if number > 1 else number  # control the model scale\n",
    "\n",
    "            if module in [Conv2D, Conv, Bottleneck, SPP, DWConv, Focus, BottleneckCSP, BottleneckCSP2, SPPCSP, VoVCSP]:\n",
    "                c2 = args[0]\n",
    "                c2 = math.ceil(c2 * width_multiple / 8) * 8 if c2 != output_dims else c2\n",
    "                args = [c2, *args[1:]]\n",
    "\n",
    "                if module in [BottleneckCSP, BottleneckCSP2, SPPCSP, VoVCSP]:\n",
    "                    args.insert(1, number)\n",
    "                    number = 1\n",
    "\n",
    "            modules = tf.keras.Sequential(*[module(*args) for _ in range(number)]) if number > 1 else module(*args)\n",
    "            modules.i, modules.f = i, f\n",
    "            layers.append(modules)\n",
    "        return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = \"/app/yolo/configs/yolo-l-mish.yaml\"\n",
    "yolo = Yolo(yaml_path)\n",
    "model = yolo(640)\n",
    "img = np.random.rand(1,640,640,3)\n",
    "pred = model(img)\n",
    "# pred = model.forward(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 80, 80, 3, 25)\n",
      "(1, 40, 40, 3, 25)\n",
      "(1, 20, 20, 3, 25)\n"
     ]
    }
   ],
   "source": [
    "print(pred[0].shape)\n",
    "print(pred[1].shape)\n",
    "print(pred[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
