{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import os \n",
    "import numpy as np\n",
    "import glob \n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import re \n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "epochs = 300\n",
    "batch_size_per_replica = 1024\n",
    "global_batch_size = batch_size_per_replica * strategy.num_replicas_in_sync\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(len(x_train)).batch(global_batch_size)\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = keras.callbacks.ModelCheckpoint(\n",
    "    \"checkpoint/\", save_weights_only=True, monitor=\"train_acc\", save_best_only=False, save_freq=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFit(keras.Model):\n",
    "    def __init__(self, model, strategy):\n",
    "        super(CustomFit, self).__init__()\n",
    "        self.model = model\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def compile(self, optimizer, loss):\n",
    "        super(CustomFit, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, inputs):\n",
    "        per_replica_losses = self.strategy.run(_train_step, args=(inputs,))\n",
    "        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "\n",
    "    def _train_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(images)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(labels, predictions))\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'logs' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-32c942ca8e06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dist_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mglobal_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;31m# Run validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'logs' referenced before assignment"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "trainer = CustomFit(model, strategy)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "trainer.compile(optimizer, loss)\n",
    "trainer.fit(train_dist_dataset, steps_per_epoch=len(train_dataset)//global_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:Error reported to Coordinator: Trying to create optimizer slot variable under the scope for tf.distribute.Strategy (<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fb8241ceb00>), which is different from the scope used for the original variable (<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 64) dtype=float32, numpy=\n",
      "array([[[[-6.86040893e-02,  8.65439475e-02, -9.90202129e-02,\n",
      "          -7.42899403e-02,  3.85516882e-02, -3.37210298e-02,\n",
      "          -4.75692488e-02, -2.98770964e-02, -4.07992341e-02,\n",
      "          -8.39507580e-02,  7.07758367e-02,  9.76625830e-02,\n",
      "           9.52724367e-02,  6.97878301e-02,  6.89488947e-02,\n",
      "           9.95609611e-02, -6.57660887e-02,  2.43334472e-03,\n",
      "          -4.03111801e-02,  8.32463801e-02, -2.82507986e-02,\n",
      "           1.18212476e-02,  9.74254459e-02, -9.64476690e-02,\n",
      "           6.24428838e-02,  9.94014740e-02, -7.85267949e-02,\n",
      "           3.06659341e-02, -7.45871216e-02,  3.84510010e-02,\n",
      "           2.71407515e-02,  7.15307891e-03, -4.17451859e-02,\n",
      "          -9.85331461e-02,  5.79175651e-02,  2.29453593e-02,\n",
      "           7.11540580e-02,  6.89872354e-02,  2.93921679e-03,\n",
      "           2.26108730e-03, -1.67177767e-02, -7.46464729e-02,\n",
      "          -1.26131624e-03, -7.34782815e-02,  6.75134808e-02,\n",
      "           1.11916736e-02, -7.38748312e-02,  1.45809203e-02,\n",
      "           5.54414392e-02, -9.74255428e-02,  5.33247292e-02,\n",
      "           2.97644287e-02,  8.61808509e-02,  6.96981698e-02,\n",
      "          -7.73961991e-02, -9.50586945e-02,  2.52721757e-02,\n",
      "           1.69953704e-03,  6.72389269e-02,  1.67497918e-02,\n",
      "           5.52151352e-03, -5.38760424e-03, -2.59551108e-02,\n",
      "           3.14582884e-03]],\n",
      "\n",
      "        [[ 4.62876558e-02,  3.20405513e-02, -4.22011763e-02,\n",
      "           4.41475213e-03, -2.25412622e-02,  6.06717318e-02,\n",
      "           9.25662369e-02, -2.41491124e-02, -8.47526789e-02,\n",
      "           5.01618534e-02, -1.00219935e-01,  7.64098763e-02,\n",
      "          -1.55689567e-02,  9.54746306e-02,  4.64342088e-02,\n",
      "           8.93022418e-02, -4.92515936e-02, -2.15461925e-02,\n",
      "          -1.06072277e-02, -1.59172043e-02, -5.15058637e-05,\n",
      "          -4.85210679e-02,  5.93472421e-02, -2.22773254e-02,\n",
      "          -1.17211863e-02, -3.15806195e-02,  9.74826515e-02,\n",
      "           7.21790344e-02,  3.84579897e-02, -2.13835537e-02,\n",
      "          -7.36769587e-02,  2.10285410e-02, -8.79548714e-02,\n",
      "          -3.39148715e-02,  6.86076581e-02,  9.20613557e-02,\n",
      "           5.08014560e-02, -3.01690176e-02,  6.00812733e-02,\n",
      "           6.14876151e-02,  8.63880366e-02,  9.09168273e-03,\n",
      "           4.96763736e-03,  8.74852687e-02, -5.86934835e-02,\n",
      "          -6.28028959e-02, -7.69736022e-02, -3.74601185e-02,\n",
      "           6.28401935e-02,  3.93548012e-02,  8.91903937e-02,\n",
      "           3.62900048e-02, -6.68363869e-02,  7.54470229e-02,\n",
      "          -7.13090450e-02,  6.95875585e-02,  7.58635998e-02,\n",
      "          -1.04738027e-02, -6.62169829e-02, -1.36953518e-02,\n",
      "          -5.22168390e-02,  9.03248489e-02, -2.23562345e-02,\n",
      "          -7.58759901e-02]],\n",
      "\n",
      "        [[-2.56763250e-02, -7.36636072e-02, -5.35677373e-03,\n",
      "           8.44714046e-02, -1.13706142e-02, -8.55117738e-02,\n",
      "          -8.45539868e-02,  5.83360791e-02,  2.55394429e-02,\n",
      "          -9.18322429e-02, -1.15457177e-02,  6.39920384e-02,\n",
      "          -5.85086010e-02, -9.25728604e-02,  3.38024050e-02,\n",
      "          -8.97997618e-02, -5.91709130e-02, -5.84760271e-02,\n",
      "           6.36033714e-02,  4.33733463e-02,  8.43169242e-02,\n",
      "          -6.86571151e-02, -2.82236338e-02, -4.77657206e-02,\n",
      "          -4.30720598e-02,  7.24513233e-02, -7.11126924e-02,\n",
      "           9.55414921e-02,  5.54861575e-02,  6.72445893e-02,\n",
      "          -4.96468320e-02,  8.71624053e-03, -3.70719060e-02,\n",
      "          -1.83882937e-02, -6.53744191e-02, -6.69645816e-02,\n",
      "           9.69964713e-02,  4.23648655e-02, -6.65498301e-02,\n",
      "          -7.65729025e-02, -2.54455358e-02,  5.13488948e-02,\n",
      "          -5.73199242e-03,  9.76211429e-02, -3.03763896e-03,\n",
      "           8.78524184e-02,  2.04591826e-02,  7.18169212e-02,\n",
      "           6.23108000e-02, -1.00750655e-01,  1.06996372e-02,\n",
      "           4.09409702e-02, -5.04910350e-02, -8.71985853e-02,\n",
      "           8.40831548e-03,  6.87701404e-02, -4.29495946e-02,\n",
      "          -4.28268127e-02, -8.77539814e-03,  3.33983749e-02,\n",
      "           7.68558979e-02, -6.53789937e-03,  4.01819497e-02,\n",
      "          -8.07937458e-02]]],\n",
      "\n",
      "\n",
      "       [[[-4.85118441e-02,  5.77395111e-02,  4.54635173e-03,\n",
      "           1.90076753e-02, -4.63295169e-02, -1.49085522e-02,\n",
      "          -7.33307078e-02,  7.21872002e-02, -6.59065694e-02,\n",
      "           2.18612477e-02, -1.07341409e-02, -7.78808743e-02,\n",
      "          -1.62013769e-02,  8.79659355e-02,  8.02125335e-02,\n",
      "           1.00507095e-01,  8.23626071e-02, -3.24570313e-02,\n",
      "           3.45887244e-02, -3.82794514e-02, -9.28833187e-02,\n",
      "           5.52288145e-02,  8.77679586e-02,  1.73700973e-02,\n",
      "          -8.84250551e-02,  8.87881815e-02, -5.95429502e-02,\n",
      "          -5.30477129e-02, -4.59129326e-02,  9.69569534e-02,\n",
      "           1.85834840e-02,  4.33155149e-02, -8.18075985e-02,\n",
      "          -3.88391204e-02,  6.32538348e-02, -1.17594004e-03,\n",
      "           9.30129588e-02,  6.93799108e-02, -5.49406074e-02,\n",
      "           7.09545463e-02,  1.80670321e-02, -8.86790678e-02,\n",
      "          -4.41231579e-03, -3.25295627e-02, -5.21665215e-02,\n",
      "           1.57205015e-03, -4.20353673e-02,  1.05431005e-02,\n",
      "          -4.80687246e-02, -6.42679781e-02, -1.40726045e-02,\n",
      "           4.60252762e-02, -5.12012094e-03,  6.85012788e-02,\n",
      "          -4.65991497e-02, -9.37242061e-03,  7.40370452e-02,\n",
      "          -3.42202857e-02, -1.28607154e-02, -2.13409066e-02,\n",
      "          -7.98755139e-03,  2.80921310e-02,  4.81798351e-02,\n",
      "           8.55995119e-02]],\n",
      "\n",
      "        [[-7.64408037e-02, -8.42198133e-02,  1.01042330e-01,\n",
      "          -6.26957119e-02, -5.72990030e-02, -5.59362248e-02,\n",
      "          -4.64233942e-02,  9.24552530e-02, -1.68706179e-02,\n",
      "           6.87842369e-02, -8.57145935e-02,  7.09469765e-02,\n",
      "          -9.57996026e-02, -7.03971833e-03,  6.34024292e-03,\n",
      "           2.93686241e-02, -1.68814585e-02, -7.52364248e-02,\n",
      "           1.14629492e-02, -2.52665207e-02, -9.77716446e-02,\n",
      "           2.14238465e-02,  3.06503326e-02,  1.67397708e-02,\n",
      "           5.93986511e-02, -1.86628997e-02,  2.97934562e-03,\n",
      "           1.00920081e-01, -5.58846742e-02, -9.67026949e-02,\n",
      "          -6.44407570e-02,  2.44665146e-03,  7.06541687e-02,\n",
      "           6.62983954e-02, -6.56247139e-05, -9.02380794e-03,\n",
      "          -2.21052393e-02,  1.01048350e-02, -6.31494075e-02,\n",
      "           5.71055263e-02, -9.93678346e-02,  4.94423211e-02,\n",
      "           3.26473415e-02, -6.45129383e-03,  7.24822581e-02,\n",
      "          -8.21753815e-02, -5.30630946e-02,  5.28360009e-02,\n",
      "           5.85414469e-03,  8.84914398e-03, -9.18776616e-02,\n",
      "          -8.56833458e-02, -8.26733634e-02, -7.83180743e-02,\n",
      "           5.96407354e-02, -8.03531706e-03, -7.19169602e-02,\n",
      "          -2.48053446e-02, -9.62215960e-02,  8.10737163e-02,\n",
      "          -1.15432367e-02,  2.48603523e-02, -6.07819557e-02,\n",
      "           3.81025821e-02]],\n",
      "\n",
      "        [[ 9.55485404e-02,  4.69856709e-02, -3.47258449e-02,\n",
      "          -6.42246082e-02, -3.61399576e-02,  5.13288677e-02,\n",
      "           9.92559493e-02,  1.18879825e-02,  4.24545109e-02,\n",
      "           9.51408446e-02,  2.93129683e-02,  7.04548210e-02,\n",
      "          -4.54118885e-02,  1.86608210e-02,  8.93689394e-02,\n",
      "          -5.97151332e-02,  2.74027735e-02,  1.05769783e-02,\n",
      "          -3.45489383e-03,  5.53792566e-02, -9.08591226e-02,\n",
      "          -4.25348207e-02,  1.48830488e-02,  6.47442043e-02,\n",
      "          -6.53964430e-02, -3.39846015e-02, -1.75799429e-03,\n",
      "           2.79904157e-02,  2.82821208e-02,  3.57938856e-02,\n",
      "          -4.58813757e-02, -4.05089818e-02, -1.84042230e-02,\n",
      "           4.18168455e-02,  4.97535616e-02, -6.68389052e-02,\n",
      "          -7.72795007e-02,  8.86817276e-02,  8.29289705e-02,\n",
      "          -4.30449694e-02, -9.22245830e-02,  5.80323786e-02,\n",
      "          -1.08365640e-02,  3.08480114e-02,  6.70372993e-02,\n",
      "          -2.43895054e-02, -2.39772201e-02,  5.40777147e-02,\n",
      "           6.91656619e-02, -4.93341461e-02, -9.44510996e-02,\n",
      "          -7.51683787e-02, -5.23728207e-02,  7.16906637e-02,\n",
      "          -3.75929922e-02,  4.69153374e-02, -6.33010417e-02,\n",
      "           1.06211826e-02,  9.10878778e-02,  3.43113095e-02,\n",
      "           6.25863820e-02,  1.11616850e-02,  4.67140526e-02,\n",
      "           7.04077631e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 7.74221271e-02,  2.72650719e-02,  4.63600606e-02,\n",
      "          -7.02948123e-03,  4.90959734e-02,  5.97970188e-03,\n",
      "          -5.40100783e-03, -9.17220414e-02,  5.42052239e-02,\n",
      "           7.89783150e-02,  1.76518708e-02,  3.91349047e-02,\n",
      "           4.06865180e-02,  9.41028744e-02,  8.94313455e-02,\n",
      "           8.71090591e-03, -6.27714321e-02,  4.84210253e-02,\n",
      "          -4.28589992e-02, -2.91124061e-02, -9.39015150e-02,\n",
      "          -8.98701251e-02, -2.88749635e-02,  9.53539908e-02,\n",
      "           1.05275959e-02,  2.15474963e-02, -7.46463537e-02,\n",
      "           3.61668319e-02,  1.80205256e-02, -9.41694826e-02,\n",
      "          -3.72334421e-02, -2.03625783e-02,  4.93571609e-02,\n",
      "           6.60390854e-02, -9.65025052e-02,  9.32852477e-02,\n",
      "           3.93625200e-02,  2.46851742e-02, -8.70423838e-02,\n",
      "          -4.99187820e-02, -4.34778035e-02,  8.67240727e-02,\n",
      "          -9.54985097e-02, -5.63649833e-03, -6.40164986e-02,\n",
      "          -6.10658340e-02, -2.43301541e-02, -4.84741516e-02,\n",
      "          -6.13258593e-02,  9.95672345e-02, -9.91410762e-03,\n",
      "           5.73570430e-02, -2.72978097e-03,  4.88315523e-03,\n",
      "           9.66714472e-02, -9.41410661e-02,  6.78424090e-02,\n",
      "           3.22461724e-02,  7.76278228e-02, -4.43776846e-02,\n",
      "          -4.86506075e-02,  4.79975641e-02,  4.46633697e-02,\n",
      "          -5.89791983e-02]],\n",
      "\n",
      "        [[ 7.17389882e-02,  2.75890082e-02,  1.36448145e-02,\n",
      "           4.91816849e-02,  5.77188879e-02, -2.08610669e-02,\n",
      "           1.69344842e-02, -7.87805319e-02, -2.02277750e-02,\n",
      "           9.50916111e-02,  2.34423727e-02, -4.85200770e-02,\n",
      "          -9.22369659e-02,  8.69222283e-02, -6.32449985e-03,\n",
      "          -2.80037522e-04, -4.02674526e-02, -7.56354779e-02,\n",
      "           1.06227323e-02,  3.09830457e-02, -9.89043862e-02,\n",
      "          -5.80039099e-02,  2.27806717e-03,  5.15855253e-02,\n",
      "          -2.98132077e-02, -4.89749312e-02, -9.02272016e-03,\n",
      "          -4.35914807e-02,  7.38992840e-02,  4.38383967e-02,\n",
      "          -8.75422731e-02, -3.44845131e-02,  4.69483435e-02,\n",
      "          -3.58592644e-02, -4.15094793e-02,  2.95970291e-02,\n",
      "          -3.29858437e-02,  3.41592729e-02,  8.91017318e-02,\n",
      "           3.90504003e-02,  8.34491998e-02, -8.34531635e-02,\n",
      "           1.75589398e-02,  4.91368473e-02, -6.99619651e-02,\n",
      "          -5.61957434e-02, -5.85797094e-02,  7.15656728e-02,\n",
      "           8.44275802e-02, -7.84234703e-02,  7.63579160e-02,\n",
      "           7.96814859e-02, -9.89569053e-02, -6.00077510e-02,\n",
      "          -2.33365148e-02,  9.19010043e-02, -8.62295255e-02,\n",
      "          -1.39763579e-02,  4.16506529e-02, -1.95030868e-03,\n",
      "          -2.64858007e-02, -8.07791352e-02, -8.93484056e-02,\n",
      "           9.88370180e-02]],\n",
      "\n",
      "        [[-3.10810953e-02,  5.64170331e-02,  1.95636004e-02,\n",
      "          -8.94613117e-02, -4.03608009e-02, -4.16243151e-02,\n",
      "           5.53193241e-02,  9.05155391e-03, -9.95140895e-02,\n",
      "          -5.43422066e-02, -7.21780211e-02,  9.14065838e-02,\n",
      "          -1.23726577e-03, -2.02825665e-03,  9.55431312e-02,\n",
      "           6.45353943e-02, -1.71093717e-02,  6.91753775e-02,\n",
      "           7.93589652e-02,  5.04209101e-02,  4.34219092e-02,\n",
      "          -4.06756327e-02, -3.72825488e-02,  9.54215974e-02,\n",
      "           1.94230005e-02,  2.48125643e-02,  1.12222210e-02,\n",
      "           8.97791237e-02, -3.09445038e-02, -8.55450928e-02,\n",
      "          -2.42140144e-02,  3.04844528e-02,  4.42568660e-02,\n",
      "           8.79810154e-02, -6.29638955e-02, -5.72592095e-02,\n",
      "          -6.65042922e-02,  8.17744881e-02,  5.10862470e-02,\n",
      "           2.87583172e-02,  7.01417029e-03, -4.10855785e-02,\n",
      "          -9.93924215e-02,  2.39948928e-02, -3.95653248e-02,\n",
      "          -2.57227570e-03, -4.23840806e-02, -8.48296806e-02,\n",
      "           6.11844212e-02, -3.30315307e-02,  7.00373948e-03,\n",
      "           6.03670329e-02, -6.42010421e-02,  9.17682499e-02,\n",
      "          -8.91030133e-02,  7.17107356e-02,  1.67998746e-02,\n",
      "          -4.97103818e-02, -8.05659294e-02, -3.02923545e-02,\n",
      "          -5.83846867e-02, -2.04286203e-02,  2.48152912e-02,\n",
      "           6.47748411e-02]]]], dtype=float32)>). Make sure the slot variables are created under the same strategy scope. This may happen if you're restoring from a checkpoint outside the scope\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py\", line 323, in run\n",
      "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 255, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 532, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 339, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 789, in run_step\n",
      "    outputs = model.train_step(data)\n",
      "  File \"<ipython-input-1-34cedb71fb90>\", line 59, in train_step\n",
      "    self.optimizer.apply_gradients(zip(gradients, training_vars))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 519, in apply_gradients\n",
      "    self._create_all_weights(var_list)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 704, in _create_all_weights\n",
      "    self._create_slots(var_list)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/adam.py\", line 127, in _create_slots\n",
      "    self.add_slot(var, 'm')\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 757, in add_slot\n",
      "    .format(strategy, var))\n",
      "ValueError: Trying to create optimizer slot variable under the scope for tf.distribute.Strategy (<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fb8241ceb00>), which is different from the scope used for the original variable (<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 64) dtype=float32, numpy=\n",
      "array([[[[-6.86040893e-02,  8.65439475e-02, -9.90202129e-02,\n",
      "          -7.42899403e-02,  3.85516882e-02, -3.37210298e-02,\n",
      "          -4.75692488e-02, -2.98770964e-02, -4.07992341e-02,\n",
      "          -8.39507580e-02,  7.07758367e-02,  9.76625830e-02,\n",
      "           9.52724367e-02,  6.97878301e-02,  6.89488947e-02,\n",
      "           9.95609611e-02, -6.57660887e-02,  2.43334472e-03,\n",
      "          -4.03111801e-02,  8.32463801e-02, -2.82507986e-02,\n",
      "           1.18212476e-02,  9.74254459e-02, -9.64476690e-02,\n",
      "           6.24428838e-02,  9.94014740e-02, -7.85267949e-02,\n",
      "           3.06659341e-02, -7.45871216e-02,  3.84510010e-02,\n",
      "           2.71407515e-02,  7.15307891e-03, -4.17451859e-02,\n",
      "          -9.85331461e-02,  5.79175651e-02,  2.29453593e-02,\n",
      "           7.11540580e-02,  6.89872354e-02,  2.93921679e-03,\n",
      "           2.26108730e-03, -1.67177767e-02, -7.46464729e-02,\n",
      "          -1.26131624e-03, -7.34782815e-02,  6.75134808e-02,\n",
      "           1.11916736e-02, -7.38748312e-02,  1.45809203e-02,\n",
      "           5.54414392e-02, -9.74255428e-02,  5.33247292e-02,\n",
      "           2.97644287e-02,  8.61808509e-02,  6.96981698e-02,\n",
      "          -7.73961991e-02, -9.50586945e-02,  2.52721757e-02,\n",
      "           1.69953704e-03,  6.72389269e-02,  1.67497918e-02,\n",
      "           5.52151352e-03, -5.38760424e-03, -2.59551108e-02,\n",
      "           3.14582884e-03]],\n",
      "\n",
      "        [[ 4.62876558e-02,  3.20405513e-02, -4.22011763e-02,\n",
      "           4.41475213e-03, -2.25412622e-02,  6.06717318e-02,\n",
      "           9.25662369e-02, -2.41491124e-02, -8.47526789e-02,\n",
      "           5.01618534e-02, -1.00219935e-01,  7.64098763e-02,\n",
      "          -1.55689567e-02,  9.54746306e-02,  4.64342088e-02,\n",
      "           8.93022418e-02, -4.92515936e-02, -2.15461925e-02,\n",
      "          -1.06072277e-02, -1.59172043e-02, -5.15058637e-05,\n",
      "          -4.85210679e-02,  5.93472421e-02, -2.22773254e-02,\n",
      "          -1.17211863e-02, -3.15806195e-02,  9.74826515e-02,\n",
      "           7.21790344e-02,  3.84579897e-02, -2.13835537e-02,\n",
      "          -7.36769587e-02,  2.10285410e-02, -8.79548714e-02,\n",
      "          -3.39148715e-02,  6.86076581e-02,  9.20613557e-02,\n",
      "           5.08014560e-02, -3.01690176e-02,  6.00812733e-02,\n",
      "           6.14876151e-02,  8.63880366e-02,  9.09168273e-03,\n",
      "           4.96763736e-03,  8.74852687e-02, -5.86934835e-02,\n",
      "          -6.28028959e-02, -7.69736022e-02, -3.74601185e-02,\n",
      "           6.28401935e-02,  3.93548012e-02,  8.91903937e-02,\n",
      "           3.62900048e-02, -6.68363869e-02,  7.54470229e-02,\n",
      "          -7.13090450e-02,  6.95875585e-02,  7.58635998e-02,\n",
      "          -1.04738027e-02, -6.62169829e-02, -1.36953518e-02,\n",
      "          -5.22168390e-02,  9.03248489e-02, -2.23562345e-02,\n",
      "          -7.58759901e-02]],\n",
      "\n",
      "        [[-2.56763250e-02, -7.36636072e-02, -5.35677373e-03,\n",
      "           8.44714046e-02, -1.13706142e-02, -8.55117738e-02,\n",
      "          -8.45539868e-02,  5.83360791e-02,  2.55394429e-02,\n",
      "          -9.18322429e-02, -1.15457177e-02,  6.39920384e-02,\n",
      "          -5.85086010e-02, -9.25728604e-02,  3.38024050e-02,\n",
      "          -8.97997618e-02, -5.91709130e-02, -5.84760271e-02,\n",
      "           6.36033714e-02,  4.33733463e-02,  8.43169242e-02,\n",
      "          -6.86571151e-02, -2.82236338e-02, -4.77657206e-02,\n",
      "          -4.30720598e-02,  7.24513233e-02, -7.11126924e-02,\n",
      "           9.55414921e-02,  5.54861575e-02,  6.72445893e-02,\n",
      "          -4.96468320e-02,  8.71624053e-03, -3.70719060e-02,\n",
      "          -1.83882937e-02, -6.53744191e-02, -6.69645816e-02,\n",
      "           9.69964713e-02,  4.23648655e-02, -6.65498301e-02,\n",
      "          -7.65729025e-02, -2.54455358e-02,  5.13488948e-02,\n",
      "          -5.73199242e-03,  9.76211429e-02, -3.03763896e-03,\n",
      "           8.78524184e-02,  2.04591826e-02,  7.18169212e-02,\n",
      "           6.23108000e-02, -1.00750655e-01,  1.06996372e-02,\n",
      "           4.09409702e-02, -5.04910350e-02, -8.71985853e-02,\n",
      "           8.40831548e-03,  6.87701404e-02, -4.29495946e-02,\n",
      "          -4.28268127e-02, -8.77539814e-03,  3.33983749e-02,\n",
      "           7.68558979e-02, -6.53789937e-03,  4.01819497e-02,\n",
      "          -8.07937458e-02]]],\n",
      "\n",
      "\n",
      "       [[[-4.85118441e-02,  5.77395111e-02,  4.54635173e-03,\n",
      "           1.90076753e-02, -4.63295169e-02, -1.49085522e-02,\n",
      "          -7.33307078e-02,  7.21872002e-02, -6.59065694e-02,\n",
      "           2.18612477e-02, -1.07341409e-02, -7.78808743e-02,\n",
      "          -1.62013769e-02,  8.79659355e-02,  8.02125335e-02,\n",
      "           1.00507095e-01,  8.23626071e-02, -3.24570313e-02,\n",
      "           3.45887244e-02, -3.82794514e-02, -9.28833187e-02,\n",
      "           5.52288145e-02,  8.77679586e-02,  1.73700973e-02,\n",
      "          -8.84250551e-02,  8.87881815e-02, -5.95429502e-02,\n",
      "          -5.30477129e-02, -4.59129326e-02,  9.69569534e-02,\n",
      "           1.85834840e-02,  4.33155149e-02, -8.18075985e-02,\n",
      "          -3.88391204e-02,  6.32538348e-02, -1.17594004e-03,\n",
      "           9.30129588e-02,  6.93799108e-02, -5.49406074e-02,\n",
      "           7.09545463e-02,  1.80670321e-02, -8.86790678e-02,\n",
      "          -4.41231579e-03, -3.25295627e-02, -5.21665215e-02,\n",
      "           1.57205015e-03, -4.20353673e-02,  1.05431005e-02,\n",
      "          -4.80687246e-02, -6.42679781e-02, -1.40726045e-02,\n",
      "           4.60252762e-02, -5.12012094e-03,  6.85012788e-02,\n",
      "          -4.65991497e-02, -9.37242061e-03,  7.40370452e-02,\n",
      "          -3.42202857e-02, -1.28607154e-02, -2.13409066e-02,\n",
      "          -7.98755139e-03,  2.80921310e-02,  4.81798351e-02,\n",
      "           8.55995119e-02]],\n",
      "\n",
      "        [[-7.64408037e-02, -8.42198133e-02,  1.01042330e-01,\n",
      "          -6.26957119e-02, -5.72990030e-02, -5.59362248e-02,\n",
      "          -4.64233942e-02,  9.24552530e-02, -1.68706179e-02,\n",
      "           6.87842369e-02, -8.57145935e-02,  7.09469765e-02,\n",
      "          -9.57996026e-02, -7.03971833e-03,  6.34024292e-03,\n",
      "           2.93686241e-02, -1.68814585e-02, -7.52364248e-02,\n",
      "           1.14629492e-02, -2.52665207e-02, -9.77716446e-02,\n",
      "           2.14238465e-02,  3.06503326e-02,  1.67397708e-02,\n",
      "           5.93986511e-02, -1.86628997e-02,  2.97934562e-03,\n",
      "           1.00920081e-01, -5.58846742e-02, -9.67026949e-02,\n",
      "          -6.44407570e-02,  2.44665146e-03,  7.06541687e-02,\n",
      "           6.62983954e-02, -6.56247139e-05, -9.02380794e-03,\n",
      "          -2.21052393e-02,  1.01048350e-02, -6.31494075e-02,\n",
      "           5.71055263e-02, -9.93678346e-02,  4.94423211e-02,\n",
      "           3.26473415e-02, -6.45129383e-03,  7.24822581e-02,\n",
      "          -8.21753815e-02, -5.30630946e-02,  5.28360009e-02,\n",
      "           5.85414469e-03,  8.84914398e-03, -9.18776616e-02,\n",
      "          -8.56833458e-02, -8.26733634e-02, -7.83180743e-02,\n",
      "           5.96407354e-02, -8.03531706e-03, -7.19169602e-02,\n",
      "          -2.48053446e-02, -9.62215960e-02,  8.10737163e-02,\n",
      "          -1.15432367e-02,  2.48603523e-02, -6.07819557e-02,\n",
      "           3.81025821e-02]],\n",
      "\n",
      "        [[ 9.55485404e-02,  4.69856709e-02, -3.47258449e-02,\n",
      "          -6.42246082e-02, -3.61399576e-02,  5.13288677e-02,\n",
      "           9.92559493e-02,  1.18879825e-02,  4.24545109e-02,\n",
      "           9.51408446e-02,  2.93129683e-02,  7.04548210e-02,\n",
      "          -4.54118885e-02,  1.86608210e-02,  8.93689394e-02,\n",
      "          -5.97151332e-02,  2.74027735e-02,  1.05769783e-02,\n",
      "          -3.45489383e-03,  5.53792566e-02, -9.08591226e-02,\n",
      "          -4.25348207e-02,  1.48830488e-02,  6.47442043e-02,\n",
      "          -6.53964430e-02, -3.39846015e-02, -1.75799429e-03,\n",
      "           2.79904157e-02,  2.82821208e-02,  3.57938856e-02,\n",
      "          -4.58813757e-02, -4.05089818e-02, -1.84042230e-02,\n",
      "           4.18168455e-02,  4.97535616e-02, -6.68389052e-02,\n",
      "          -7.72795007e-02,  8.86817276e-02,  8.29289705e-02,\n",
      "          -4.30449694e-02, -9.22245830e-02,  5.80323786e-02,\n",
      "          -1.08365640e-02,  3.08480114e-02,  6.70372993e-02,\n",
      "          -2.43895054e-02, -2.39772201e-02,  5.40777147e-02,\n",
      "           6.91656619e-02, -4.93341461e-02, -9.44510996e-02,\n",
      "          -7.51683787e-02, -5.23728207e-02,  7.16906637e-02,\n",
      "          -3.75929922e-02,  4.69153374e-02, -6.33010417e-02,\n",
      "           1.06211826e-02,  9.10878778e-02,  3.43113095e-02,\n",
      "           6.25863820e-02,  1.11616850e-02,  4.67140526e-02,\n",
      "           7.04077631e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 7.74221271e-02,  2.72650719e-02,  4.63600606e-02,\n",
      "          -7.02948123e-03,  4.90959734e-02,  5.97970188e-03,\n",
      "          -5.40100783e-03, -9.17220414e-02,  5.42052239e-02,\n",
      "           7.89783150e-02,  1.76518708e-02,  3.91349047e-02,\n",
      "           4.06865180e-02,  9.41028744e-02,  8.94313455e-02,\n",
      "           8.71090591e-03, -6.27714321e-02,  4.84210253e-02,\n",
      "          -4.28589992e-02, -2.91124061e-02, -9.39015150e-02,\n",
      "          -8.98701251e-02, -2.88749635e-02,  9.53539908e-02,\n",
      "           1.05275959e-02,  2.15474963e-02, -7.46463537e-02,\n",
      "           3.61668319e-02,  1.80205256e-02, -9.41694826e-02,\n",
      "          -3.72334421e-02, -2.03625783e-02,  4.93571609e-02,\n",
      "           6.60390854e-02, -9.65025052e-02,  9.32852477e-02,\n",
      "           3.93625200e-02,  2.46851742e-02, -8.70423838e-02,\n",
      "          -4.99187820e-02, -4.34778035e-02,  8.67240727e-02,\n",
      "          -9.54985097e-02, -5.63649833e-03, -6.40164986e-02,\n",
      "          -6.10658340e-02, -2.43301541e-02, -4.84741516e-02,\n",
      "          -6.13258593e-02,  9.95672345e-02, -9.91410762e-03,\n",
      "           5.73570430e-02, -2.72978097e-03,  4.88315523e-03,\n",
      "           9.66714472e-02, -9.41410661e-02,  6.78424090e-02,\n",
      "           3.22461724e-02,  7.76278228e-02, -4.43776846e-02,\n",
      "          -4.86506075e-02,  4.79975641e-02,  4.46633697e-02,\n",
      "          -5.89791983e-02]],\n",
      "\n",
      "        [[ 7.17389882e-02,  2.75890082e-02,  1.36448145e-02,\n",
      "           4.91816849e-02,  5.77188879e-02, -2.08610669e-02,\n",
      "           1.69344842e-02, -7.87805319e-02, -2.02277750e-02,\n",
      "           9.50916111e-02,  2.34423727e-02, -4.85200770e-02,\n",
      "          -9.22369659e-02,  8.69222283e-02, -6.32449985e-03,\n",
      "          -2.80037522e-04, -4.02674526e-02, -7.56354779e-02,\n",
      "           1.06227323e-02,  3.09830457e-02, -9.89043862e-02,\n",
      "          -5.80039099e-02,  2.27806717e-03,  5.15855253e-02,\n",
      "          -2.98132077e-02, -4.89749312e-02, -9.02272016e-03,\n",
      "          -4.35914807e-02,  7.38992840e-02,  4.38383967e-02,\n",
      "          -8.75422731e-02, -3.44845131e-02,  4.69483435e-02,\n",
      "          -3.58592644e-02, -4.15094793e-02,  2.95970291e-02,\n",
      "          -3.29858437e-02,  3.41592729e-02,  8.91017318e-02,\n",
      "           3.90504003e-02,  8.34491998e-02, -8.34531635e-02,\n",
      "           1.75589398e-02,  4.91368473e-02, -6.99619651e-02,\n",
      "          -5.61957434e-02, -5.85797094e-02,  7.15656728e-02,\n",
      "           8.44275802e-02, -7.84234703e-02,  7.63579160e-02,\n",
      "           7.96814859e-02, -9.89569053e-02, -6.00077510e-02,\n",
      "          -2.33365148e-02,  9.19010043e-02, -8.62295255e-02,\n",
      "          -1.39763579e-02,  4.16506529e-02, -1.95030868e-03,\n",
      "          -2.64858007e-02, -8.07791352e-02, -8.93484056e-02,\n",
      "           9.88370180e-02]],\n",
      "\n",
      "        [[-3.10810953e-02,  5.64170331e-02,  1.95636004e-02,\n",
      "          -8.94613117e-02, -4.03608009e-02, -4.16243151e-02,\n",
      "           5.53193241e-02,  9.05155391e-03, -9.95140895e-02,\n",
      "          -5.43422066e-02, -7.21780211e-02,  9.14065838e-02,\n",
      "          -1.23726577e-03, -2.02825665e-03,  9.55431312e-02,\n",
      "           6.45353943e-02, -1.71093717e-02,  6.91753775e-02,\n",
      "           7.93589652e-02,  5.04209101e-02,  4.34219092e-02,\n",
      "          -4.06756327e-02, -3.72825488e-02,  9.54215974e-02,\n",
      "           1.94230005e-02,  2.48125643e-02,  1.12222210e-02,\n",
      "           8.97791237e-02, -3.09445038e-02, -8.55450928e-02,\n",
      "          -2.42140144e-02,  3.04844528e-02,  4.42568660e-02,\n",
      "           8.79810154e-02, -6.29638955e-02, -5.72592095e-02,\n",
      "          -6.65042922e-02,  8.17744881e-02,  5.10862470e-02,\n",
      "           2.87583172e-02,  7.01417029e-03, -4.10855785e-02,\n",
      "          -9.93924215e-02,  2.39948928e-02, -3.95653248e-02,\n",
      "          -2.57227570e-03, -4.23840806e-02, -8.48296806e-02,\n",
      "           6.11844212e-02, -3.30315307e-02,  7.00373948e-03,\n",
      "           6.03670329e-02, -6.42010421e-02,  9.17682499e-02,\n",
      "          -8.91030133e-02,  7.17107356e-02,  1.67998746e-02,\n",
      "          -4.97103818e-02, -8.05659294e-02, -3.02923545e-02,\n",
      "          -5.83846867e-02, -2.04286203e-02,  2.48152912e-02,\n",
      "           6.47748411e-02]]]], dtype=float32)>). Make sure the slot variables are created under the same strategy scope. This may happen if you're restoring from a checkpoint outside the scope\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_strategy.py:585 _call_for_each_replica\n        self._container_strategy(), fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py:96 call_for_each_replica\n        return _call_for_each_replica(strategy, fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py:237 _call_for_each_replica\n        coord.join(threads)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py:389 join\n        six.reraise(*self._exc_info_to_raise)\n    /usr/local/lib/python3.6/dist-packages/six.py:703 reraise\n        raise value\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\n        yield\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py:323 run\n        self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-1-34cedb71fb90>:59 train_step\n        self.optimizer.apply_gradients(zip(gradients, training_vars))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:519 apply_gradients\n        self._create_all_weights(var_list)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:704 _create_all_weights\n        self._create_slots(var_list)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/adam.py:127 _create_slots\n        self.add_slot(var, 'm')\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:757 add_slot\n        .format(strategy, var))\n\n    ValueError: Trying to create optimizer slot variable under the scope for tf.distribute.Strategy (<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fb8241ceb00>), which is different from the scope used for the original variable (<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 64) dtype=float32, numpy=\n    array([[[[-6.86040893e-02,  8.65439475e-02, -9.90202129e-02,\n              -7.42899403e-02,  3.85516882e-02, -3.37210298e-02,\n              -4.75692488e-02, -2.98770964e-02, -4.07992341e-02,\n              -8.39507580e-02,  7.07758367e-02,  9.76625830e-02,\n               9.52724367e-02,  6.97878301e-02,  6.89488947e-02,\n               9.95609611e-02, -6.57660887e-02,  2.43334472e-03,\n              -4.03111801e-02,  8.32463801e-02, -2.82507986e-02,\n               1.18212476e-02,  9.74254459e-02, -9.64476690e-02,\n               6.24428838e-02,  9.94014740e-02, -7.85267949e-02,\n               3.06659341e-02, -7.45871216e-02,  3.84510010e-02,\n               2.71407515e-02,  7.15307891e-03, -4.17451859e-02,\n              -9.85331461e-02,  5.79175651e-02,  2.29453593e-02,\n               7.11540580e-02,  6.89872354e-02,  2.93921679e-03,\n               2.26108730e-03, -1.67177767e-02, -7.46464729e-02,\n              -1.26131624e-03, -7.34782815e-02,  6.75134808e-02,\n               1.11916736e-02, -7.38748312e-02,  1.45809203e-02,\n               5.54414392e-02, -9.74255428e-02,  5.33247292e-02,\n               2.97644287e-02,  8.61808509e-02,  6.96981698e-02,\n              -7.73961991e-02, -9.50586945e-02,  2.52721757e-02,\n               1.69953704e-03,  6.72389269e-02,  1.67497918e-02,\n               5.52151352e-03, -5.38760424e-03, -2.59551108e-02,\n               3.14582884e-03]],\n    \n            [[ 4.62876558e-02,  3.20405513e-02, -4.22011763e-02,\n               4.41475213e-03, -2.25412622e-02,  6.06717318e-02,\n               9.25662369e-02, -2.41491124e-02, -8.47526789e-02,\n               5.01618534e-02, -1.00219935e-01,  7.64098763e-02,\n              -1.55689567e-02,  9.54746306e-02,  4.64342088e-02,\n               8.93022418e-02, -4.92515936e-02, -2.15461925e-02,\n              -1.06072277e-02, -1.59172043e-02, -5.15058637e-05,\n              -4.85210679e-02,  5.93472421e-02, -2.22773254e-02,\n              -1.17211863e-02, -3.15806195e-02,  9.74826515e-02,\n               7.21790344e-02,  3.84579897e-02, -2.13835537e-02,\n              -7.36769587e-02,  2.10285410e-02, -8.79548714e-02,\n              -3.39148715e-02,  6.86076581e-02,  9.20613557e-02,\n               5.08014560e-02, -3.01690176e-02,  6.00812733e-02,\n               6.14876151e-02,  8.63880366e-02,  9.09168273e-03,\n               4.96763736e-03,  8.74852687e-02, -5.86934835e-02,\n              -6.28028959e-02, -7.69736022e-02, -3.74601185e-02,\n               6.28401935e-02,  3.93548012e-02,  8.91903937e-02,\n               3.62900048e-02, -6.68363869e-02,  7.54470229e-02,\n              -7.13090450e-02,  6.95875585e-02,  7.58635998e-02,\n              -1.04738027e-02, -6.62169829e-02, -1.36953518e-02,\n              -5.22168390e-02,  9.03248489e-02, -2.23562345e-02,\n              -7.58759901e-02]],\n    \n            [[-2.56763250e-02, -7.36636072e-02, -5.35677373e-03,\n               8.44714046e-02, -1.13706142e-02, -8.55117738e-02,\n              -8.45539868e-02,  5.83360791e-02,  2.55394429e-02,\n              -9.18322429e-02, -1.15457177e-02,  6.39920384e-02,\n              -5.85086010e-02, -9.25728604e-02,  3.38024050e-02,\n              -8.97997618e-02, -5.91709130e-02, -5.84760271e-02,\n               6.36033714e-02,  4.33733463e-02,  8.43169242e-02,\n              -6.86571151e-02, -2.82236338e-02, -4.77657206e-02,\n              -4.30720598e-02,  7.24513233e-02, -7.11126924e-02,\n               9.55414921e-02,  5.54861575e-02,  6.72445893e-02,\n              -4.96468320e-02,  8.71624053e-03, -3.70719060e-02,\n              -1.83882937e-02, -6.53744191e-02, -6.69645816e-02,\n               9.69964713e-02,  4.23648655e-02, -6.65498301e-02,\n              -7.65729025e-02, -2.54455358e-02,  5.13488948e-02,\n              -5.73199242e-03,  9.76211429e-02, -3.03763896e-03,\n               8.78524184e-02,  2.04591826e-02,  7.18169212e-02,\n               6.23108000e-02, -1.00750655e-01,  1.06996372e-02,\n               4.09409702e-02, -5.04910350e-02, -8.71985853e-02,\n               8.40831548e-03,  6.87701404e-02, -4.29495946e-02,\n              -4.28268127e-02, -8.77539814e-03,  3.33983749e-02,\n               7.68558979e-02, -6.53789937e-03,  4.01819497e-02,\n              -8.07937458e-02]]],\n    \n    \n           [[[-4.85118441e-02,  5.77395111e-02,  4.54635173e-03,\n               1.90076753e-02, -4.63295169e-02, -1.49085522e-02,\n              -7.33307078e-02,  7.21872002e-02, -6.59065694e-02,\n               2.18612477e-02, -1.07341409e-02, -7.78808743e-02,\n              -1.62013769e-02,  8.79659355e-02,  8.02125335e-02,\n               1.00507095e-01,  8.23626071e-02, -3.24570313e-02,\n               3.45887244e-02, -3.82794514e-02, -9.28833187e-02,\n               5.52288145e-02,  8.77679586e-02,  1.73700973e-02,\n              -8.84250551e-02,  8.87881815e-02, -5.95429502e-02,\n              -5.30477129e-02, -4.59129326e-02,  9.69569534e-02,\n               1.85834840e-02,  4.33155149e-02, -8.18075985e-02,\n              -3.88391204e-02,  6.32538348e-02, -1.17594004e-03,\n               9.30129588e-02,  6.93799108e-02, -5.49406074e-02,\n               7.09545463e-02,  1.80670321e-02, -8.86790678e-02,\n              -4.41231579e-03, -3.25295627e-02, -5.21665215e-02,\n               1.57205015e-03, -4.20353673e-02,  1.05431005e-02,\n              -4.80687246e-02, -6.42679781e-02, -1.40726045e-02,\n               4.60252762e-02, -5.12012094e-03,  6.85012788e-02,\n              -4.65991497e-02, -9.37242061e-03,  7.40370452e-02,\n              -3.42202857e-02, -1.28607154e-02, -2.13409066e-02,\n              -7.98755139e-03,  2.80921310e-02,  4.81798351e-02,\n               8.55995119e-02]],\n    \n            [[-7.64408037e-02, -8.42198133e-02,  1.01042330e-01,\n              -6.26957119e-02, -5.72990030e-02, -5.59362248e-02,\n              -4.64233942e-02,  9.24552530e-02, -1.68706179e-02,\n               6.87842369e-02, -8.57145935e-02,  7.09469765e-02,\n              -9.57996026e-02, -7.03971833e-03,  6.34024292e-03,\n               2.93686241e-02, -1.68814585e-02, -7.52364248e-02,\n               1.14629492e-02, -2.52665207e-02, -9.77716446e-02,\n               2.14238465e-02,  3.06503326e-02,  1.67397708e-02,\n               5.93986511e-02, -1.86628997e-02,  2.97934562e-03,\n               1.00920081e-01, -5.58846742e-02, -9.67026949e-02,\n              -6.44407570e-02,  2.44665146e-03,  7.06541687e-02,\n               6.62983954e-02, -6.56247139e-05, -9.02380794e-03,\n              -2.21052393e-02,  1.01048350e-02, -6.31494075e-02,\n               5.71055263e-02, -9.93678346e-02,  4.94423211e-02,\n               3.26473415e-02, -6.45129383e-03,  7.24822581e-02,\n              -8.21753815e-02, -5.30630946e-02,  5.28360009e-02,\n               5.85414469e-03,  8.84914398e-03, -9.18776616e-02,\n              -8.56833458e-02, -8.26733634e-02, -7.83180743e-02,\n               5.96407354e-02, -8.03531706e-03, -7.19169602e-02,\n              -2.48053446e-02, -9.62215960e-02,  8.10737163e-02,\n              -1.15432367e-02,  2.48603523e-02, -6.07819557e-02,\n               3.81025821e-02]],\n    \n            [[ 9.55485404e-02,  4.69856709e-02, -3.47258449e-02,\n              -6.42246082e-02, -3.61399576e-02,  5.13288677e-02,\n               9.92559493e-02,  1.18879825e-02,  4.24545109e-02,\n               9.51408446e-02,  2.93129683e-02,  7.04548210e-02,\n              -4.54118885e-02,  1.86608210e-02,  8.93689394e-02,\n              -5.97151332e-02,  2.74027735e-02,  1.05769783e-02,\n              -3.45489383e-03,  5.53792566e-02, -9.08591226e-02,\n              -4.25348207e-02,  1.48830488e-02,  6.47442043e-02,\n              -6.53964430e-02, -3.39846015e-02, -1.75799429e-03,\n               2.79904157e-02,  2.82821208e-02,  3.57938856e-02,\n              -4.58813757e-02, -4.05089818e-02, -1.84042230e-02,\n               4.18168455e-02,  4.97535616e-02, -6.68389052e-02,\n              -7.72795007e-02,  8.86817276e-02,  8.29289705e-02,\n              -4.30449694e-02, -9.22245830e-02,  5.80323786e-02,\n              -1.08365640e-02,  3.08480114e-02,  6.70372993e-02,\n              -2.43895054e-02, -2.39772201e-02,  5.40777147e-02,\n               6.91656619e-02, -4.93341461e-02, -9.44510996e-02,\n              -7.51683787e-02, -5.23728207e-02,  7.16906637e-02,\n              -3.75929922e-02,  4.69153374e-02, -6.33010417e-02,\n               1.06211826e-02,  9.10878778e-02,  3.43113095e-02,\n               6.25863820e-02,  1.11616850e-02,  4.67140526e-02,\n               7.04077631e-02]]],\n    \n    \n           [[[ 7.74221271e-02,  2.72650719e-02,  4.63600606e-02,\n              -7.02948123e-03,  4.90959734e-02,  5.97970188e-03,\n              -5.40100783e-03, -9.17220414e-02,  5.42052239e-02,\n               7.89783150e-02,  1.76518708e-02,  3.91349047e-02,\n               4.06865180e-02,  9.41028744e-02,  8.94313455e-02,\n               8.71090591e-03, -6.27714321e-02,  4.84210253e-02,\n              -4.28589992e-02, -2.91124061e-02, -9.39015150e-02,\n              -8.98701251e-02, -2.88749635e-02,  9.53539908e-02,\n               1.05275959e-02,  2.15474963e-02, -7.46463537e-02,\n               3.61668319e-02,  1.80205256e-02, -9.41694826e-02,\n              -3.72334421e-02, -2.03625783e-02,  4.93571609e-02,\n               6.60390854e-02, -9.65025052e-02,  9.32852477e-02,\n               3.93625200e-02,  2.46851742e-02, -8.70423838e-02,\n              -4.99187820e-02, -4.34778035e-02,  8.67240727e-02,\n              -9.54985097e-02, -5.63649833e-03, -6.40164986e-02,\n              -6.10658340e-02, -2.43301541e-02, -4.84741516e-02,\n              -6.13258593e-02,  9.95672345e-02, -9.91410762e-03,\n               5.73570430e-02, -2.72978097e-03,  4.88315523e-03,\n               9.66714472e-02, -9.41410661e-02,  6.78424090e-02,\n               3.22461724e-02,  7.76278228e-02, -4.43776846e-02,\n              -4.86506075e-02,  4.79975641e-02,  4.46633697e-02,\n              -5.89791983e-02]],\n    \n            [[ 7.17389882e-02,  2.75890082e-02,  1.36448145e-02,\n               4.91816849e-02,  5.77188879e-02, -2.08610669e-02,\n               1.69344842e-02, -7.87805319e-02, -2.02277750e-02,\n               9.50916111e-02,  2.34423727e-02, -4.85200770e-02,\n              -9.22369659e-02,  8.69222283e-02, -6.32449985e-03,\n              -2.80037522e-04, -4.02674526e-02, -7.56354779e-02,\n               1.06227323e-02,  3.09830457e-02, -9.89043862e-02,\n              -5.80039099e-02,  2.27806717e-03,  5.15855253e-02,\n              -2.98132077e-02, -4.89749312e-02, -9.02272016e-03,\n              -4.35914807e-02,  7.38992840e-02,  4.38383967e-02,\n              -8.75422731e-02, -3.44845131e-02,  4.69483435e-02,\n              -3.58592644e-02, -4.15094793e-02,  2.95970291e-02,\n              -3.29858437e-02,  3.41592729e-02,  8.91017318e-02,\n               3.90504003e-02,  8.34491998e-02, -8.34531635e-02,\n               1.75589398e-02,  4.91368473e-02, -6.99619651e-02,\n              -5.61957434e-02, -5.85797094e-02,  7.15656728e-02,\n               8.44275802e-02, -7.84234703e-02,  7.63579160e-02,\n               7.96814859e-02, -9.89569053e-02, -6.00077510e-02,\n              -2.33365148e-02,  9.19010043e-02, -8.62295255e-02,\n              -1.39763579e-02,  4.16506529e-02, -1.95030868e-03,\n              -2.64858007e-02, -8.07791352e-02, -8.93484056e-02,\n               9.88370180e-02]],\n    \n            [[-3.10810953e-02,  5.64170331e-02,  1.95636004e-02,\n              -8.94613117e-02, -4.03608009e-02, -4.16243151e-02,\n               5.53193241e-02,  9.05155391e-03, -9.95140895e-02,\n              -5.43422066e-02, -7.21780211e-02,  9.14065838e-02,\n              -1.23726577e-03, -2.02825665e-03,  9.55431312e-02,\n               6.45353943e-02, -1.71093717e-02,  6.91753775e-02,\n               7.93589652e-02,  5.04209101e-02,  4.34219092e-02,\n              -4.06756327e-02, -3.72825488e-02,  9.54215974e-02,\n               1.94230005e-02,  2.48125643e-02,  1.12222210e-02,\n               8.97791237e-02, -3.09445038e-02, -8.55450928e-02,\n              -2.42140144e-02,  3.04844528e-02,  4.42568660e-02,\n               8.79810154e-02, -6.29638955e-02, -5.72592095e-02,\n              -6.65042922e-02,  8.17744881e-02,  5.10862470e-02,\n               2.87583172e-02,  7.01417029e-03, -4.10855785e-02,\n              -9.93924215e-02,  2.39948928e-02, -3.95653248e-02,\n              -2.57227570e-03, -4.23840806e-02, -8.48296806e-02,\n               6.11844212e-02, -3.30315307e-02,  7.00373948e-03,\n               6.03670329e-02, -6.42010421e-02,  9.17682499e-02,\n              -8.91030133e-02,  7.17107356e-02,  1.67998746e-02,\n              -4.97103818e-02, -8.05659294e-02, -3.02923545e-02,\n              -5.83846867e-02, -2.04286203e-02,  2.48152912e-02,\n               6.47748411e-02]]]], dtype=float32)>). Make sure the slot variables are created under the same strategy scope. This may happen if you're restoring from a checkpoint outside the scope\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-34cedb71fb90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_strategy.py:585 _call_for_each_replica\n        self._container_strategy(), fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py:96 call_for_each_replica\n        return _call_for_each_replica(strategy, fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py:237 _call_for_each_replica\n        coord.join(threads)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py:389 join\n        six.reraise(*self._exc_info_to_raise)\n    /usr/local/lib/python3.6/dist-packages/six.py:703 reraise\n        raise value\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\n        yield\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py:323 run\n        self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-1-34cedb71fb90>:59 train_step\n        self.optimizer.apply_gradients(zip(gradients, training_vars))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:519 apply_gradients\n        self._create_all_weights(var_list)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:704 _create_all_weights\n        self._create_slots(var_list)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/adam.py:127 _create_slots\n        self.add_slot(var, 'm')\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:757 add_slot\n        .format(strategy, var))\n\n    ValueError: Trying to create optimizer slot variable under the scope for tf.distribute.Strategy (<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fb8241ceb00>), which is different from the scope used for the original variable (<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 64) dtype=float32, numpy=\n    array([[[[-6.86040893e-02,  8.65439475e-02, -9.90202129e-02,\n              -7.42899403e-02,  3.85516882e-02, -3.37210298e-02,\n              -4.75692488e-02, -2.98770964e-02, -4.07992341e-02,\n              -8.39507580e-02,  7.07758367e-02,  9.76625830e-02,\n               9.52724367e-02,  6.97878301e-02,  6.89488947e-02,\n               9.95609611e-02, -6.57660887e-02,  2.43334472e-03,\n              -4.03111801e-02,  8.32463801e-02, -2.82507986e-02,\n               1.18212476e-02,  9.74254459e-02, -9.64476690e-02,\n               6.24428838e-02,  9.94014740e-02, -7.85267949e-02,\n               3.06659341e-02, -7.45871216e-02,  3.84510010e-02,\n               2.71407515e-02,  7.15307891e-03, -4.17451859e-02,\n              -9.85331461e-02,  5.79175651e-02,  2.29453593e-02,\n               7.11540580e-02,  6.89872354e-02,  2.93921679e-03,\n               2.26108730e-03, -1.67177767e-02, -7.46464729e-02,\n              -1.26131624e-03, -7.34782815e-02,  6.75134808e-02,\n               1.11916736e-02, -7.38748312e-02,  1.45809203e-02,\n               5.54414392e-02, -9.74255428e-02,  5.33247292e-02,\n               2.97644287e-02,  8.61808509e-02,  6.96981698e-02,\n              -7.73961991e-02, -9.50586945e-02,  2.52721757e-02,\n               1.69953704e-03,  6.72389269e-02,  1.67497918e-02,\n               5.52151352e-03, -5.38760424e-03, -2.59551108e-02,\n               3.14582884e-03]],\n    \n            [[ 4.62876558e-02,  3.20405513e-02, -4.22011763e-02,\n               4.41475213e-03, -2.25412622e-02,  6.06717318e-02,\n               9.25662369e-02, -2.41491124e-02, -8.47526789e-02,\n               5.01618534e-02, -1.00219935e-01,  7.64098763e-02,\n              -1.55689567e-02,  9.54746306e-02,  4.64342088e-02,\n               8.93022418e-02, -4.92515936e-02, -2.15461925e-02,\n              -1.06072277e-02, -1.59172043e-02, -5.15058637e-05,\n              -4.85210679e-02,  5.93472421e-02, -2.22773254e-02,\n              -1.17211863e-02, -3.15806195e-02,  9.74826515e-02,\n               7.21790344e-02,  3.84579897e-02, -2.13835537e-02,\n              -7.36769587e-02,  2.10285410e-02, -8.79548714e-02,\n              -3.39148715e-02,  6.86076581e-02,  9.20613557e-02,\n               5.08014560e-02, -3.01690176e-02,  6.00812733e-02,\n               6.14876151e-02,  8.63880366e-02,  9.09168273e-03,\n               4.96763736e-03,  8.74852687e-02, -5.86934835e-02,\n              -6.28028959e-02, -7.69736022e-02, -3.74601185e-02,\n               6.28401935e-02,  3.93548012e-02,  8.91903937e-02,\n               3.62900048e-02, -6.68363869e-02,  7.54470229e-02,\n              -7.13090450e-02,  6.95875585e-02,  7.58635998e-02,\n              -1.04738027e-02, -6.62169829e-02, -1.36953518e-02,\n              -5.22168390e-02,  9.03248489e-02, -2.23562345e-02,\n              -7.58759901e-02]],\n    \n            [[-2.56763250e-02, -7.36636072e-02, -5.35677373e-03,\n               8.44714046e-02, -1.13706142e-02, -8.55117738e-02,\n              -8.45539868e-02,  5.83360791e-02,  2.55394429e-02,\n              -9.18322429e-02, -1.15457177e-02,  6.39920384e-02,\n              -5.85086010e-02, -9.25728604e-02,  3.38024050e-02,\n              -8.97997618e-02, -5.91709130e-02, -5.84760271e-02,\n               6.36033714e-02,  4.33733463e-02,  8.43169242e-02,\n              -6.86571151e-02, -2.82236338e-02, -4.77657206e-02,\n              -4.30720598e-02,  7.24513233e-02, -7.11126924e-02,\n               9.55414921e-02,  5.54861575e-02,  6.72445893e-02,\n              -4.96468320e-02,  8.71624053e-03, -3.70719060e-02,\n              -1.83882937e-02, -6.53744191e-02, -6.69645816e-02,\n               9.69964713e-02,  4.23648655e-02, -6.65498301e-02,\n              -7.65729025e-02, -2.54455358e-02,  5.13488948e-02,\n              -5.73199242e-03,  9.76211429e-02, -3.03763896e-03,\n               8.78524184e-02,  2.04591826e-02,  7.18169212e-02,\n               6.23108000e-02, -1.00750655e-01,  1.06996372e-02,\n               4.09409702e-02, -5.04910350e-02, -8.71985853e-02,\n               8.40831548e-03,  6.87701404e-02, -4.29495946e-02,\n              -4.28268127e-02, -8.77539814e-03,  3.33983749e-02,\n               7.68558979e-02, -6.53789937e-03,  4.01819497e-02,\n              -8.07937458e-02]]],\n    \n    \n           [[[-4.85118441e-02,  5.77395111e-02,  4.54635173e-03,\n               1.90076753e-02, -4.63295169e-02, -1.49085522e-02,\n              -7.33307078e-02,  7.21872002e-02, -6.59065694e-02,\n               2.18612477e-02, -1.07341409e-02, -7.78808743e-02,\n              -1.62013769e-02,  8.79659355e-02,  8.02125335e-02,\n               1.00507095e-01,  8.23626071e-02, -3.24570313e-02,\n               3.45887244e-02, -3.82794514e-02, -9.28833187e-02,\n               5.52288145e-02,  8.77679586e-02,  1.73700973e-02,\n              -8.84250551e-02,  8.87881815e-02, -5.95429502e-02,\n              -5.30477129e-02, -4.59129326e-02,  9.69569534e-02,\n               1.85834840e-02,  4.33155149e-02, -8.18075985e-02,\n              -3.88391204e-02,  6.32538348e-02, -1.17594004e-03,\n               9.30129588e-02,  6.93799108e-02, -5.49406074e-02,\n               7.09545463e-02,  1.80670321e-02, -8.86790678e-02,\n              -4.41231579e-03, -3.25295627e-02, -5.21665215e-02,\n               1.57205015e-03, -4.20353673e-02,  1.05431005e-02,\n              -4.80687246e-02, -6.42679781e-02, -1.40726045e-02,\n               4.60252762e-02, -5.12012094e-03,  6.85012788e-02,\n              -4.65991497e-02, -9.37242061e-03,  7.40370452e-02,\n              -3.42202857e-02, -1.28607154e-02, -2.13409066e-02,\n              -7.98755139e-03,  2.80921310e-02,  4.81798351e-02,\n               8.55995119e-02]],\n    \n            [[-7.64408037e-02, -8.42198133e-02,  1.01042330e-01,\n              -6.26957119e-02, -5.72990030e-02, -5.59362248e-02,\n              -4.64233942e-02,  9.24552530e-02, -1.68706179e-02,\n               6.87842369e-02, -8.57145935e-02,  7.09469765e-02,\n              -9.57996026e-02, -7.03971833e-03,  6.34024292e-03,\n               2.93686241e-02, -1.68814585e-02, -7.52364248e-02,\n               1.14629492e-02, -2.52665207e-02, -9.77716446e-02,\n               2.14238465e-02,  3.06503326e-02,  1.67397708e-02,\n               5.93986511e-02, -1.86628997e-02,  2.97934562e-03,\n               1.00920081e-01, -5.58846742e-02, -9.67026949e-02,\n              -6.44407570e-02,  2.44665146e-03,  7.06541687e-02,\n               6.62983954e-02, -6.56247139e-05, -9.02380794e-03,\n              -2.21052393e-02,  1.01048350e-02, -6.31494075e-02,\n               5.71055263e-02, -9.93678346e-02,  4.94423211e-02,\n               3.26473415e-02, -6.45129383e-03,  7.24822581e-02,\n              -8.21753815e-02, -5.30630946e-02,  5.28360009e-02,\n               5.85414469e-03,  8.84914398e-03, -9.18776616e-02,\n              -8.56833458e-02, -8.26733634e-02, -7.83180743e-02,\n               5.96407354e-02, -8.03531706e-03, -7.19169602e-02,\n              -2.48053446e-02, -9.62215960e-02,  8.10737163e-02,\n              -1.15432367e-02,  2.48603523e-02, -6.07819557e-02,\n               3.81025821e-02]],\n    \n            [[ 9.55485404e-02,  4.69856709e-02, -3.47258449e-02,\n              -6.42246082e-02, -3.61399576e-02,  5.13288677e-02,\n               9.92559493e-02,  1.18879825e-02,  4.24545109e-02,\n               9.51408446e-02,  2.93129683e-02,  7.04548210e-02,\n              -4.54118885e-02,  1.86608210e-02,  8.93689394e-02,\n              -5.97151332e-02,  2.74027735e-02,  1.05769783e-02,\n              -3.45489383e-03,  5.53792566e-02, -9.08591226e-02,\n              -4.25348207e-02,  1.48830488e-02,  6.47442043e-02,\n              -6.53964430e-02, -3.39846015e-02, -1.75799429e-03,\n               2.79904157e-02,  2.82821208e-02,  3.57938856e-02,\n              -4.58813757e-02, -4.05089818e-02, -1.84042230e-02,\n               4.18168455e-02,  4.97535616e-02, -6.68389052e-02,\n              -7.72795007e-02,  8.86817276e-02,  8.29289705e-02,\n              -4.30449694e-02, -9.22245830e-02,  5.80323786e-02,\n              -1.08365640e-02,  3.08480114e-02,  6.70372993e-02,\n              -2.43895054e-02, -2.39772201e-02,  5.40777147e-02,\n               6.91656619e-02, -4.93341461e-02, -9.44510996e-02,\n              -7.51683787e-02, -5.23728207e-02,  7.16906637e-02,\n              -3.75929922e-02,  4.69153374e-02, -6.33010417e-02,\n               1.06211826e-02,  9.10878778e-02,  3.43113095e-02,\n               6.25863820e-02,  1.11616850e-02,  4.67140526e-02,\n               7.04077631e-02]]],\n    \n    \n           [[[ 7.74221271e-02,  2.72650719e-02,  4.63600606e-02,\n              -7.02948123e-03,  4.90959734e-02,  5.97970188e-03,\n              -5.40100783e-03, -9.17220414e-02,  5.42052239e-02,\n               7.89783150e-02,  1.76518708e-02,  3.91349047e-02,\n               4.06865180e-02,  9.41028744e-02,  8.94313455e-02,\n               8.71090591e-03, -6.27714321e-02,  4.84210253e-02,\n              -4.28589992e-02, -2.91124061e-02, -9.39015150e-02,\n              -8.98701251e-02, -2.88749635e-02,  9.53539908e-02,\n               1.05275959e-02,  2.15474963e-02, -7.46463537e-02,\n               3.61668319e-02,  1.80205256e-02, -9.41694826e-02,\n              -3.72334421e-02, -2.03625783e-02,  4.93571609e-02,\n               6.60390854e-02, -9.65025052e-02,  9.32852477e-02,\n               3.93625200e-02,  2.46851742e-02, -8.70423838e-02,\n              -4.99187820e-02, -4.34778035e-02,  8.67240727e-02,\n              -9.54985097e-02, -5.63649833e-03, -6.40164986e-02,\n              -6.10658340e-02, -2.43301541e-02, -4.84741516e-02,\n              -6.13258593e-02,  9.95672345e-02, -9.91410762e-03,\n               5.73570430e-02, -2.72978097e-03,  4.88315523e-03,\n               9.66714472e-02, -9.41410661e-02,  6.78424090e-02,\n               3.22461724e-02,  7.76278228e-02, -4.43776846e-02,\n              -4.86506075e-02,  4.79975641e-02,  4.46633697e-02,\n              -5.89791983e-02]],\n    \n            [[ 7.17389882e-02,  2.75890082e-02,  1.36448145e-02,\n               4.91816849e-02,  5.77188879e-02, -2.08610669e-02,\n               1.69344842e-02, -7.87805319e-02, -2.02277750e-02,\n               9.50916111e-02,  2.34423727e-02, -4.85200770e-02,\n              -9.22369659e-02,  8.69222283e-02, -6.32449985e-03,\n              -2.80037522e-04, -4.02674526e-02, -7.56354779e-02,\n               1.06227323e-02,  3.09830457e-02, -9.89043862e-02,\n              -5.80039099e-02,  2.27806717e-03,  5.15855253e-02,\n              -2.98132077e-02, -4.89749312e-02, -9.02272016e-03,\n              -4.35914807e-02,  7.38992840e-02,  4.38383967e-02,\n              -8.75422731e-02, -3.44845131e-02,  4.69483435e-02,\n              -3.58592644e-02, -4.15094793e-02,  2.95970291e-02,\n              -3.29858437e-02,  3.41592729e-02,  8.91017318e-02,\n               3.90504003e-02,  8.34491998e-02, -8.34531635e-02,\n               1.75589398e-02,  4.91368473e-02, -6.99619651e-02,\n              -5.61957434e-02, -5.85797094e-02,  7.15656728e-02,\n               8.44275802e-02, -7.84234703e-02,  7.63579160e-02,\n               7.96814859e-02, -9.89569053e-02, -6.00077510e-02,\n              -2.33365148e-02,  9.19010043e-02, -8.62295255e-02,\n              -1.39763579e-02,  4.16506529e-02, -1.95030868e-03,\n              -2.64858007e-02, -8.07791352e-02, -8.93484056e-02,\n               9.88370180e-02]],\n    \n            [[-3.10810953e-02,  5.64170331e-02,  1.95636004e-02,\n              -8.94613117e-02, -4.03608009e-02, -4.16243151e-02,\n               5.53193241e-02,  9.05155391e-03, -9.95140895e-02,\n              -5.43422066e-02, -7.21780211e-02,  9.14065838e-02,\n              -1.23726577e-03, -2.02825665e-03,  9.55431312e-02,\n               6.45353943e-02, -1.71093717e-02,  6.91753775e-02,\n               7.93589652e-02,  5.04209101e-02,  4.34219092e-02,\n              -4.06756327e-02, -3.72825488e-02,  9.54215974e-02,\n               1.94230005e-02,  2.48125643e-02,  1.12222210e-02,\n               8.97791237e-02, -3.09445038e-02, -8.55450928e-02,\n              -2.42140144e-02,  3.04844528e-02,  4.42568660e-02,\n               8.79810154e-02, -6.29638955e-02, -5.72592095e-02,\n              -6.65042922e-02,  8.17744881e-02,  5.10862470e-02,\n               2.87583172e-02,  7.01417029e-03, -4.10855785e-02,\n              -9.93924215e-02,  2.39948928e-02, -3.95653248e-02,\n              -2.57227570e-03, -4.23840806e-02, -8.48296806e-02,\n               6.11844212e-02, -3.30315307e-02,  7.00373948e-03,\n               6.03670329e-02, -6.42010421e-02,  9.17682499e-02,\n              -8.91030133e-02,  7.17107356e-02,  1.67998746e-02,\n              -4.97103818e-02, -8.05659294e-02, -3.02923545e-02,\n              -5.83846867e-02, -2.04286203e-02,  2.48152912e-02,\n               6.47748411e-02]]]], dtype=float32)>). Make sure the slot variables are created under the same strategy scope. This may happen if you're restoring from a checkpoint outside the scope\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "epochs = 300\n",
    "batch_size_per_replica = 1024\n",
    "global_batch_size = batch_size_per_replica * mirrored_strategy.num_replicas_in_sync\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(len(x_train)).batch(global_batch_size)\n",
    "train_dist_dataset = mirrored_strategy.experimental_distribute_dataset(train_dataset)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(64, (3, 3), padding=\"same\"),\n",
    "        layers.ReLU(),\n",
    "        layers.Conv2D(128, (3, 3), padding=\"same\"),\n",
    "        layers.ReLU(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10),\n",
    "    ],\n",
    "    name=\"model\",\n",
    ")\n",
    "\n",
    "class CustomFit(keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(CustomFit, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def compile(self, optimizer, loss):\n",
    "        super(CustomFit, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Caclulate predictions\n",
    "            y_pred = self.model(x, training=True)\n",
    "\n",
    "            # Loss\n",
    "            loss = self.loss(y, y_pred)\n",
    "\n",
    "        # Gradients\n",
    "        training_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, training_vars)\n",
    "\n",
    "        # Step with optimizer\n",
    "        self.optimizer.apply_gradients(zip(gradients, training_vars))\n",
    "        acc_metric.update_state(y, y_pred)\n",
    "\n",
    "        return {\"loss\": loss, \"accuracy\": acc_metric.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions\n",
    "        y_pred = self.model(x, training=False)\n",
    "\n",
    "        # Updates the metrics tracking the loss\n",
    "        loss = self.loss(y, y_pred)\n",
    "\n",
    "        # Update the metrics.\n",
    "        acc_metric.update_state(y, y_pred)\n",
    "        return {\"loss\": loss, \"accuracy\": acc_metric.result()}\n",
    "\n",
    "    acc_metric = keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
    "\n",
    "# Define mirrored strategy\n",
    "# mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    training = CustomFit(model)\n",
    "    training.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM), # Specify reduction method\n",
    "    )\n",
    "\n",
    "    training.fit(x_train, y_train, batch_size=64, epochs=2)\n",
    "    training.evaluate(x_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
