{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization,Activation, MaxPool2D, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "import re\n",
    "import os \n",
    "import glob \n",
    "import random\n",
    "import logging\n",
    "from tensorflow.keras import backend as K\n",
    "import math\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", use_bias=False)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_unet(input_shape, n_classes):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    c1, p1 = encoder_block(inputs, 16)\n",
    "    c2, p2 = encoder_block(p1, 32)\n",
    "    c3, p3 = encoder_block(p2, 64)\n",
    "    c4, p4 = encoder_block(p3, 128)\n",
    "\n",
    "    c5 = conv_block(p4, 256) #Bridge\n",
    "    c6 = decoder_block(c5, c4, 128)\n",
    "    c7 = decoder_block(c6, c3, 64)\n",
    "    c8 = decoder_block(c7, c2, 32)\n",
    "    c9 = decoder_block(c8, c1, 16)\n",
    "\n",
    "    if n_classes == 1:  #Binary\n",
    "        activation = 'sigmoid'\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "    \n",
    "    outputs = Conv2D(n_classes, 1, padding=\"same\", activation=activation)(c9)\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader(object):\n",
    "    def __init__(self, img_dir, mask_dir, is_training=True, img_size=(128, 128)):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.imgs_path = glob.glob(f\"{self.img_dir}/*.jpg\")\n",
    "        self.num_imgs = len(self.imgs_path)\n",
    "        self.img_h, self.img_w = img_size\n",
    "        self.is_training = is_training\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_imgs\n",
    "    \n",
    "    \n",
    "    def find_mask(self, img_path):\n",
    "        mask_path = re.sub(self.img_dir, self.mask_dir, img_path)\n",
    "        mask_path = re.sub(\".jpg\", \".png\", mask_path)\n",
    "        return mask_path if os.path.exists(mask_path) else None\n",
    "    \n",
    "    \n",
    "    def load_normalized_resize_img(self, img_path, is_mask=False, resize_method=tf.image.ResizeMethod.BILINEAR):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        channels = 1 if is_mask else 3\n",
    "        # tf.image.decode_image if passing dtype=tf.float32, the value is range from [0,1] no need to normalized again \n",
    "        img = tf.image.decode_image(img, channels=channels, dtype=tf.float32)\n",
    "        img = tf.image.resize_with_pad(img, self.img_h, self.img_w, method=resize_method)\n",
    "        return img\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs_path[index]\n",
    "        mask_path = self.find_mask(img_path)\n",
    "        \n",
    "        img = self.load_normalized_resize_img(img_path)\n",
    "        if mask_path:\n",
    "            mask = self.load_normalized_resize_img(mask_path, is_mask=True)\n",
    "        else:\n",
    "            mask = tf.zeros((self.img_h, self.img_w, 1), dtype=tf.float32)\n",
    "        mask = tf.where(mask > 0, 1., 0)\n",
    "        \n",
    "        if self.is_training:\n",
    "            img, mask = self.geo_transform(img, mask)\n",
    "            img = self.color_transform(img)\n",
    "            img = tf.clip_by_value(img, 0, 1)\n",
    "        \n",
    "        return img, mask \n",
    "    \n",
    "    \n",
    "    def iter(self):\n",
    "        for i in range(self.num_imgs):\n",
    "            yield self[i]\n",
    "            \n",
    "    \n",
    "    def geo_transform(self, img, mask):\n",
    "        random_number = random.random()\n",
    "        if random_number < 0.2:\n",
    "            img = tf.image.flip_left_right(img)\n",
    "            mask = tf.image.flip_left_right(mask)\n",
    "        elif random_number < 0.4:\n",
    "            img = tf.image.flip_up_down(img)\n",
    "            mask = tf.image.flip_up_down(mask)\n",
    "        elif random_number < 0.6:\n",
    "            img = tf.image.rot90(img, 1)\n",
    "            mask = tf.image.rot90(mask, 1)\n",
    "        elif random_number < 0.8:\n",
    "            img = tf.image.rot90(img, 3)\n",
    "            mask = tf.image.rot90(mask, 3)\n",
    "        return img, mask \n",
    "    \n",
    "    \n",
    "    def color_transform(self, img):\n",
    "        random_number = random.random()\n",
    "        if random_number < 0.2:\n",
    "            img = tf.image.adjust_gamma(img, 0.6)\n",
    "        elif random_number < 0.6:\n",
    "            img = tf.image.random_brightness(img, max_delta=0.1)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loss function and metrics\n",
    "\"\"\"\n",
    "def jaccard_coefficient(y_true, y_pred, smooth=1.):\n",
    "    y_true_flatten = K.flatten(y_true)\n",
    "    y_pred_flatten = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_flatten * y_pred_flatten)\n",
    "    union = K.sum(y_true_flatten) + K.sum(y_pred_flatten) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "\n",
    "def jaccard_loss(y_true, y_pred):\n",
    "    return 1 - jaccard_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coefficient(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "BATCH_PER_REPLICAS = 32\n",
    "GLOBAL_BATCH = BATCH_PER_REPLICAS * NUM_REPLICAS\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "img_dir = \"/app/seg/data/seg_training/images\"\n",
    "label_dir = \"/app/seg/data/seg_training/labels\"\n",
    "data_reader = DataReader(img_dir, label_dir, is_training=True, img_size=(128, 128))\n",
    "dataset = tf.data.Dataset.from_generator(data_reader.iter,\n",
    "                                         output_types=(tf.float32, tf.float32),\n",
    "                                         output_shapes=([128, 128, 3], [128, 128, 1]))\n",
    "dataset = dataset.batch(GLOBAL_BATCH, drop_remainder=True).prefetch(AUTOTUNE)\n",
    "# dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "num_examples = len(data_reader)\n",
    "steps_per_epoch = num_examples // GLOBAL_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "59/59 [==============================] - 54s 908ms/step - loss: 0.4703 - jaccard_coefficient: 0.5297\n",
      "Epoch 2/50\n",
      "59/59 [==============================] - 53s 907ms/step - loss: 0.3338 - jaccard_coefficient: 0.6662\n",
      "Epoch 3/50\n",
      "59/59 [==============================] - 54s 909ms/step - loss: 0.2660 - jaccard_coefficient: 0.7340\n",
      "Epoch 4/50\n",
      "59/59 [==============================] - 52s 885ms/step - loss: 0.2295 - jaccard_coefficient: 0.7705\n",
      "Epoch 5/50\n",
      "59/59 [==============================] - 53s 900ms/step - loss: 0.2112 - jaccard_coefficient: 0.7888\n",
      "Epoch 6/50\n",
      "59/59 [==============================] - 54s 907ms/step - loss: 0.2004 - jaccard_coefficient: 0.7996\n",
      "Epoch 7/50\n",
      "59/59 [==============================] - 53s 904ms/step - loss: 0.1921 - jaccard_coefficient: 0.8079\n",
      "Epoch 8/50\n",
      "59/59 [==============================] - 53s 891ms/step - loss: 0.1870 - jaccard_coefficient: 0.8130\n",
      "Epoch 9/50\n",
      "59/59 [==============================] - 52s 888ms/step - loss: 0.1805 - jaccard_coefficient: 0.8195\n",
      "Epoch 10/50\n",
      "59/59 [==============================] - 54s 921ms/step - loss: 0.1791 - jaccard_coefficient: 0.8209\n",
      "Epoch 11/50\n",
      "59/59 [==============================] - 54s 909ms/step - loss: 0.1763 - jaccard_coefficient: 0.8237\n",
      "Epoch 12/50\n",
      "59/59 [==============================] - 53s 901ms/step - loss: 0.1729 - jaccard_coefficient: 0.8271\n",
      "Epoch 13/50\n",
      "59/59 [==============================] - 53s 895ms/step - loss: 0.1714 - jaccard_coefficient: 0.8286\n",
      "Epoch 14/50\n",
      "59/59 [==============================] - 54s 911ms/step - loss: 0.1682 - jaccard_coefficient: 0.8318\n",
      "Epoch 15/50\n",
      "59/59 [==============================] - 54s 912ms/step - loss: 0.1661 - jaccard_coefficient: 0.8339\n",
      "Epoch 16/50\n",
      "59/59 [==============================] - 53s 898ms/step - loss: 0.1655 - jaccard_coefficient: 0.8345\n",
      "Epoch 17/50\n",
      "59/59 [==============================] - 54s 924ms/step - loss: 0.1637 - jaccard_coefficient: 0.8363\n",
      "Epoch 18/50\n",
      "59/59 [==============================] - 54s 913ms/step - loss: 0.1618 - jaccard_coefficient: 0.8382\n",
      "Epoch 19/50\n",
      "59/59 [==============================] - 54s 913ms/step - loss: 0.1595 - jaccard_coefficient: 0.8405\n",
      "Epoch 20/50\n",
      "59/59 [==============================] - 55s 930ms/step - loss: 0.1586 - jaccard_coefficient: 0.8414\n",
      "Epoch 21/50\n",
      "59/59 [==============================] - 53s 904ms/step - loss: 0.1568 - jaccard_coefficient: 0.8432\n",
      "Epoch 22/50\n",
      "59/59 [==============================] - 53s 902ms/step - loss: 0.1565 - jaccard_coefficient: 0.8435\n",
      "Epoch 23/50\n",
      "59/59 [==============================] - 54s 919ms/step - loss: 0.1564 - jaccard_coefficient: 0.8436\n",
      "Epoch 24/50\n",
      "59/59 [==============================] - 54s 909ms/step - loss: 0.1563 - jaccard_coefficient: 0.8437\n",
      "Epoch 25/50\n",
      "59/59 [==============================] - 53s 903ms/step - loss: 0.1545 - jaccard_coefficient: 0.8455\n",
      "Epoch 26/50\n",
      "59/59 [==============================] - 54s 912ms/step - loss: 0.1535 - jaccard_coefficient: 0.8465\n",
      "Epoch 27/50\n",
      "59/59 [==============================] - 54s 919ms/step - loss: 0.1531 - jaccard_coefficient: 0.8469\n",
      "Epoch 28/50\n",
      "59/59 [==============================] - 53s 895ms/step - loss: 0.1510 - jaccard_coefficient: 0.8490\n",
      "Epoch 29/50\n",
      "59/59 [==============================] - 54s 909ms/step - loss: 0.1500 - jaccard_coefficient: 0.8500\n",
      "Epoch 30/50\n",
      "59/59 [==============================] - 53s 902ms/step - loss: 0.1503 - jaccard_coefficient: 0.8497\n",
      "Epoch 31/50\n",
      "59/59 [==============================] - 54s 921ms/step - loss: 0.1505 - jaccard_coefficient: 0.8495\n",
      "Epoch 32/50\n",
      "59/59 [==============================] - 54s 913ms/step - loss: 0.1485 - jaccard_coefficient: 0.8515\n",
      "Epoch 33/50\n",
      "59/59 [==============================] - 53s 892ms/step - loss: 0.1461 - jaccard_coefficient: 0.8539\n",
      "Epoch 34/50\n",
      "59/59 [==============================] - 53s 895ms/step - loss: 0.1471 - jaccard_coefficient: 0.8529\n",
      "Epoch 35/50\n",
      "59/59 [==============================] - 53s 899ms/step - loss: 0.1462 - jaccard_coefficient: 0.8538\n",
      "Epoch 36/50\n",
      "59/59 [==============================] - 54s 909ms/step - loss: 0.1474 - jaccard_coefficient: 0.8526\n",
      "Epoch 37/50\n",
      "59/59 [==============================] - 54s 919ms/step - loss: 0.1448 - jaccard_coefficient: 0.8552\n",
      "Epoch 38/50\n",
      "59/59 [==============================] - 54s 921ms/step - loss: 0.1441 - jaccard_coefficient: 0.8559\n",
      "Epoch 39/50\n",
      "59/59 [==============================] - 54s 919ms/step - loss: 0.1445 - jaccard_coefficient: 0.8555\n",
      "Epoch 40/50\n",
      "59/59 [==============================] - 55s 932ms/step - loss: 0.1442 - jaccard_coefficient: 0.8558\n",
      "Epoch 41/50\n",
      "59/59 [==============================] - 56s 941ms/step - loss: 0.1422 - jaccard_coefficient: 0.8578\n",
      "Epoch 42/50\n",
      "59/59 [==============================] - 55s 932ms/step - loss: 0.1419 - jaccard_coefficient: 0.8581\n",
      "Epoch 43/50\n",
      "59/59 [==============================] - 55s 931ms/step - loss: 0.1420 - jaccard_coefficient: 0.8580\n",
      "Epoch 44/50\n",
      "59/59 [==============================] - 54s 916ms/step - loss: 0.1410 - jaccard_coefficient: 0.8590\n",
      "Epoch 45/50\n",
      "59/59 [==============================] - 54s 911ms/step - loss: 0.1413 - jaccard_coefficient: 0.8587\n",
      "Epoch 46/50\n",
      "59/59 [==============================] - 55s 925ms/step - loss: 0.1395 - jaccard_coefficient: 0.8605\n",
      "Epoch 47/50\n",
      "59/59 [==============================] - 54s 909ms/step - loss: 0.1377 - jaccard_coefficient: 0.8623\n",
      "Epoch 48/50\n",
      "59/59 [==============================] - 54s 910ms/step - loss: 0.1381 - jaccard_coefficient: 0.8619\n",
      "Epoch 49/50\n",
      "59/59 [==============================] - 54s 921ms/step - loss: 0.1383 - jaccard_coefficient: 0.8617\n",
      "Epoch 50/50\n",
      "59/59 [==============================] - 53s 895ms/step - loss: 0.1387 - jaccard_coefficient: 0.8613\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = build_unet(input_shape=(128,128,3), n_classes=1)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss=jaccard_loss, metrics=[jaccard_coefficient])\n",
    "#, steps_per_epoch=steps_per_epoch\n",
    "history = model.fit(dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"jaccard_coefficient_mode.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/app/seg/jaccard_coefficient_mode.h5\"\n",
    "model = build_unet(input_shape=(128,128,3), n_classes=1)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=jaccard_loss, metrics=[jaccard_coefficient])\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset(dataset_dir):\n",
    "    files = glob.glob(dataset_dir + \"/*.jpg\")\n",
    "    print(len(files))\n",
    "    for file in files:\n",
    "        image = Image.open(file)\n",
    "        image = image.resize((128, 128))\n",
    "        image = np.array(image) / 255.\n",
    "        yield [image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/app/seg/data/images/train\"\n",
    "rep = representative_dataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(1, 128, 128, 3)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 128, 128, 16) 432         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 128, 128, 16) 64          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 128, 128, 16) 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 128, 128, 16) 2304        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 128, 128, 16) 64          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 128, 128, 16) 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 64, 64, 16)   0           activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 64, 64, 32)   4608        max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 64, 64, 32)   128         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 64, 64, 32)   0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 64, 64, 32)   9216        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 64, 64, 32)   128         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 64, 64, 32)   0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 32, 32, 32)   0           activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 32, 32, 64)   18432       max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 32, 32, 64)   256         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 32, 32, 64)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 32, 32, 64)   36864       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 32, 32, 64)   256         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 32, 32, 64)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 16, 16, 64)   0           activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 128)  73728       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 16, 16, 128)  512         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 16, 16, 128)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 128)  147456      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 16, 16, 128)  512         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 16, 16, 128)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 8, 8, 128)    0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 8, 8, 256)    294912      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 256)    1024        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 256)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 8, 8, 256)    589824      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 8, 8, 256)    1024        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 8, 8, 256)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DTran (None, 16, 16, 128)  131200      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 256)  0           conv2d_transpose_20[0][0]        \n",
      "                                                                 activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 128)  294912      concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 16, 128)  512         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 128)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 128)  147456      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 128)  512         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 128)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DTran (None, 32, 32, 64)   32832       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 32, 32, 128)  0           conv2d_transpose_21[0][0]        \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 32, 32, 64)   73728       concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 32, 32, 64)   256         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 32, 32, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 32, 32, 64)   36864       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 32, 32, 64)   256         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 32, 32, 64)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DTran (None, 64, 64, 32)   8224        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 64, 64, 64)   0           conv2d_transpose_22[0][0]        \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 64, 64, 32)   18432       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 64, 64, 32)   128         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 64, 64, 32)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 64, 64, 32)   9216        activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 64, 64, 32)   128         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 64, 64, 32)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DTran (None, 128, 128, 16) 2064        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 128, 128, 32) 0           conv2d_transpose_23[0][0]        \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 128, 128, 16) 4608        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 128, 128, 16) 64          conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 128, 128, 16) 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 128, 128, 16) 2304        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 128, 128, 16) 64          conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 128, 128, 16) 0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 128, 128, 1)  17          activation_107[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,945,521\n",
      "Trainable params: 1,942,577\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.input.set_shape((1,) + model.input.shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-119aeb2c54b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentative_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupported_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpsSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLITE_BUILTINS_INT8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# converter.inference_input_type = tf.uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not callable"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = rep\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# converter.inference_input_type = tf.uint8\n",
    "# converter.inference_output_type = tf.uint8\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# save_path = \"/app/seg/jac_model.tflite\"\n",
    "\n",
    "# with open(save_path, 'wb') as f:\n",
    "#     f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
