{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import os \n",
    "import numpy as np\n",
    "import glob \n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import re \n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size_per_replica = 1024\n",
    "global_batch_size = batch_size_per_replica * strategy.num_replicas_in_sync\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(len(x_train)).batch(global_batch_size)\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import * \n",
    "yaml_path = \"/app/yolo/configs/yolo-l-mish.yaml\"\n",
    "yolo = Yolo(yaml_path)\n",
    "model = yolo(640)\n",
    "img = np.random.rand(1,640,640,3)\n",
    "pred = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(1, 80, 80, 3, 25)\n"
     ]
    }
   ],
   "source": [
    "print(len(pred))\n",
    "print(pred[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "313/313 - 2s - loss: 0.9255 - accuracy: 0.7993\n",
      "\n",
      "Test accuracy: 0.7993000149726868\n",
      "Epoch 0, Loss: 7.3449554443359375\n",
      "Epoch 1, Loss: 2.3911659717559814\n",
      "313/313 - 2s - loss: 0.2841 - accuracy: 0.9156\n",
      "\n",
      "Test accuracy: 0.9156000018119812\n",
      "Epoch 2, Loss: 1.4871591329574585\n",
      "Epoch 3, Loss: 1.0891121625900269\n",
      "313/313 - 2s - loss: 0.1699 - accuracy: 0.9499\n",
      "\n",
      "Test accuracy: 0.9498999714851379\n",
      "Epoch 4, Loss: 0.8423815965652466\n",
      "Epoch 5, Loss: 0.6643686294555664\n",
      "313/313 - 2s - loss: 0.1111 - accuracy: 0.9673\n",
      "\n",
      "Test accuracy: 0.9672999978065491\n",
      "Epoch 6, Loss: 0.5459531545639038\n",
      "Epoch 7, Loss: 0.4578568637371063\n",
      "313/313 - 2s - loss: 0.0850 - accuracy: 0.9742\n",
      "\n",
      "Test accuracy: 0.9742000102996826\n",
      "Epoch 8, Loss: 0.3948487639427185\n",
      "Epoch 9, Loss: 0.35344627499580383\n",
      "313/313 - 2s - loss: 0.0670 - accuracy: 0.9801\n",
      "\n",
      "Test accuracy: 0.9800999760627747\n",
      "Epoch 10, Loss: 0.32092273235321045\n",
      "Epoch 11, Loss: 0.29047536849975586\n",
      "313/313 - 2s - loss: 0.0647 - accuracy: 0.9804\n",
      "\n",
      "Test accuracy: 0.980400025844574\n",
      "Epoch 12, Loss: 0.28659141063690186\n",
      "Epoch 13, Loss: 0.28404781222343445\n",
      "313/313 - 2s - loss: 0.0627 - accuracy: 0.9807\n",
      "\n",
      "Test accuracy: 0.9807000160217285\n",
      "Epoch 14, Loss: 0.28074994683265686\n",
      "Epoch 15, Loss: 0.2764208912849426\n",
      "313/313 - 2s - loss: 0.0623 - accuracy: 0.9812\n",
      "\n",
      "Test accuracy: 0.9811999797821045\n",
      "Epoch 16, Loss: 0.27366331219673157\n",
      "Epoch 17, Loss: 0.2722291946411133\n",
      "313/313 - 2s - loss: 0.0613 - accuracy: 0.9811\n",
      "\n",
      "Test accuracy: 0.9811000227928162\n",
      "Epoch 18, Loss: 0.270087867975235\n",
      "Epoch 19, Loss: 0.267154723405838\n",
      "313/313 - 1s - loss: 0.0599 - accuracy: 0.9820\n",
      "\n",
      "Test accuracy: 0.9819999933242798\n",
      "Epoch 20, Loss: 0.26494893431663513\n",
      "Epoch 21, Loss: 0.26174196600914\n",
      "313/313 - 2s - loss: 0.0595 - accuracy: 0.9820\n",
      "\n",
      "Test accuracy: 0.9819999933242798\n",
      "Epoch 22, Loss: 0.2606956660747528\n",
      "Epoch 23, Loss: 0.25832825899124146\n",
      "313/313 - 2s - loss: 0.0580 - accuracy: 0.9823\n",
      "\n",
      "Test accuracy: 0.9822999835014343\n",
      "Epoch 24, Loss: 0.25533127784729004\n",
      "Epoch 25, Loss: 0.25314417481422424\n",
      "313/313 - 1s - loss: 0.0571 - accuracy: 0.9829\n",
      "\n",
      "Test accuracy: 0.9829000234603882\n",
      "Epoch 26, Loss: 0.2501254081726074\n",
      "Epoch 27, Loss: 0.2472255825996399\n",
      "313/313 - 1s - loss: 0.0553 - accuracy: 0.9832\n",
      "\n",
      "Test accuracy: 0.9832000136375427\n",
      "Epoch 28, Loss: 0.24423082172870636\n",
      "Epoch 29, Loss: 0.2423987239599228\n"
     ]
    }
   ],
   "source": [
    "# Create model inside the strategy scope\n",
    "with strategy.scope():\n",
    "    # Create and compile the model\n",
    "    model = create_model()\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Define checkpoint directory\n",
    "checkpoint_dir = './checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "\n",
    "# Define training step\n",
    "@tf.function\n",
    "def distributed_train_step(inputs):\n",
    "    per_replica_losses = strategy.run(train_step, args=(inputs,))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "\n",
    "def train_step(inputs):\n",
    "    images, labels = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(labels, predictions))\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for x in train_dist_dataset:\n",
    "        total_loss += distributed_train_step(x)\n",
    "        num_batches += 1\n",
    "    train_loss = total_loss / num_batches\n",
    "    \n",
    "    # learning rate decay\n",
    "    if epoch == 3:\n",
    "        optimizer.lr = 1e-3\n",
    "    elif epoch == 10:\n",
    "        optimizer.lr = 1e-4\n",
    "        \n",
    "    # save checkpoint \n",
    "    if epoch % 2 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "        \n",
    "    # eval checkpoint \n",
    "    if epoch % 2 == 0:\n",
    "        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "        print('\\nTest accuracy:', test_acc)\n",
    "    \n",
    "    print('Epoch {}, Loss: {}'.format(epoch, train_loss))\n",
    "    \n",
    "# Evaluate the model\n",
    "# test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "# print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t     ckpt-2.index\n",
      "ckpt-1.data-00000-of-00001   ckpt-3.data-00000-of-00001\n",
      "ckpt-1.index\t\t     ckpt-3.index\n",
      "ckpt-10.data-00000-of-00001  ckpt-4.data-00000-of-00001\n",
      "ckpt-10.index\t\t     ckpt-4.index\n",
      "ckpt-11.data-00000-of-00001  ckpt-5.data-00000-of-00001\n",
      "ckpt-11.index\t\t     ckpt-5.index\n",
      "ckpt-12.data-00000-of-00001  ckpt-6.data-00000-of-00001\n",
      "ckpt-12.index\t\t     ckpt-6.index\n",
      "ckpt-13.data-00000-of-00001  ckpt-7.data-00000-of-00001\n",
      "ckpt-13.index\t\t     ckpt-7.index\n",
      "ckpt-14.data-00000-of-00001  ckpt-8.data-00000-of-00001\n",
      "ckpt-14.index\t\t     ckpt-8.index\n",
      "ckpt-15.data-00000-of-00001  ckpt-9.data-00000-of-00001\n",
      "ckpt-15.index\t\t     ckpt-9.index\n",
      "ckpt-2.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 % 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
