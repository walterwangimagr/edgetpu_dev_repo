{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os \n",
    "import numpy as np\n",
    "import glob \n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLODataReader(object):\n",
    "    def __init__(self, img_dir, label_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.imgs_path = glob.glob(f\"{self.img_dir}/*.jpg\")\n",
    "        self.idx = len(self.imgs_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs_path[index]\n",
    "        label_path = self.find_label(img_path)\n",
    "        img = self.load_img(img_path)\n",
    "        label = self.load_label(label_path)\n",
    "        return img, label \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_path)\n",
    "\n",
    "    def iter(self):\n",
    "        for i in range(self.idx):\n",
    "            yield self[i]\n",
    "\n",
    "    def load_img(self, img_path):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_image(img, channels=3, dtype=tf.float32)\n",
    "        img = tf.image.resize(img, (640,640))\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def load_label(self, label_path):\n",
    "        if os.path.exists(label_path) and os.path.getsize(label_path) > 0:\n",
    "            labels = []\n",
    "            with open(label_path, \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    label = line.strip().split()\n",
    "                    label = list(map(float, label)) # [cls, x, y, w, h]\n",
    "                    labels.append(label)    \n",
    "            labels = np.array(labels)\n",
    "            labels = np.roll(labels, -1) # [cls, x, y, w, h] ->  [x y w h cls]\n",
    "        \n",
    "        else:\n",
    "            labels = np.zeros((1, 5), np.float32)\n",
    "\n",
    "        return labels\n",
    "    \n",
    "    \n",
    "    def find_label(self, img_path):\n",
    "        label_path = re.sub(self.img_dir, self.label_dir, img_path)\n",
    "        label_path = re.sub(\".jpg\", \".txt\", label_path)\n",
    "        return label_path if os.path.exists(label_path) else None\n",
    "\n",
    "    \n",
    "    def load_img_and_label(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "        img = self.load_img(img_path)\n",
    "        label_path = self.find_label(img_path)\n",
    "        label = self.load_label(label_path)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    '''\n",
    "    data pipeline from data_reader (image,label) to tf.data\n",
    "    '''\n",
    "    def __init__(self, data_reader, anchors, stride, img_size=640, anchor_assign_method='wh',\n",
    "                 anchor_positive_augment=True):\n",
    "        self.data_reader = data_reader\n",
    "        self.img_size = img_size\n",
    "        self.anchor_label = AnchorLabeler(anchors,\n",
    "                                          grids=img_size / stride,\n",
    "                                          img_size=img_size,\n",
    "                                          assign_method=anchor_assign_method,\n",
    "                                          extend_offset=anchor_positive_augment)\n",
    "        \n",
    "    def __call__(self, batch_size=8, anchor_label=True):\n",
    "        dataset = tf.data.Dataset.from_generator(self.data_reader.iter,\n",
    "                                                 output_types=(tf.float32, tf.float32),\n",
    "                                                 output_shapes=([self.img_size, self.img_size, 3], [None, 5]))\n",
    "        \n",
    "        if anchor_label:  # when train\n",
    "            dataset = dataset.map(self.transform, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        return dataset\n",
    "    \n",
    "    \n",
    "    def transform(self, image, label):\n",
    "        label_encoder = self.anchor_label.encode(label)\n",
    "        return image, label_encoder\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorLabeler(object):\n",
    "    # transfer the annotated label to model target by anchor encoding, to calculate anchor based loss next step\n",
    "    def __init__(self, anchors, grids, img_size=640, assign_method='wh', extend_offset=True, rect_style='rect4', anchor_match_threshold=4.0):  # 4.0 or 0.3\n",
    "        self.anchors = anchors  # from yaml.anchors to Detect.anchors, w/h based on grid coordinators\n",
    "        self.grids = grids\n",
    "        self.img_size = img_size\n",
    "        self.assign_method = assign_method\n",
    "        self.extend_offset = extend_offset\n",
    "        self.rect_style = rect_style\n",
    "        self.anchor_match_threshold = anchor_match_threshold\n",
    "\n",
    "    def encode(self, labels):\n",
    "        ''' This is important for Yolo series.\n",
    "        key part is: assign the label to which anchor and which grid, new encoding method of V4 solved the grid sensitivity problem\n",
    "        labels: (n_bs * n_gt * 5), x/y/w/h/class, normalized image coordinators\n",
    "        anchors: (3 * 3 * 2), scale * anchor_per_scale * wh,\n",
    "        return: [[], [], []]\n",
    "        '''\n",
    "        \n",
    "        self.num_scales = self.anchors.shape[0]\n",
    "        self.n_anchor_per_scale = self.anchors.shape[1]\n",
    "        y_anchor_encode = []\n",
    "        gain = tf.ones(5, tf.float32)\n",
    "\n",
    "        for i in range(self.num_scales):\n",
    "            anchor = self.anchors[i]\n",
    "            grid_size = tf.cast(self.grids[i], tf.int32)\n",
    "            # 6 (xywh objectness cls)\n",
    "            y_true = tf.zeros([grid_size, grid_size, self.n_anchor_per_scale, 6], tf.float32)\n",
    "            gain = tf.tensor_scatter_nd_update(gain, [[0], [1], [2], [3]], [grid_size] * 4)\n",
    "            scaled_labels = labels * gain  # label coordinator now is the same with anchors\n",
    "\n",
    "            if labels is not None:\n",
    "                # (n_bs * n_gt * 2)\n",
    "                gt_wh = scaled_labels[..., 2:4]  # n_gt * 2\n",
    "                if self.assign_method == 'wh':\n",
    "                    assert self.anchor_match_threshold > 1, 'threshold is totally different for wh and iou assign'\n",
    "                    matched_matrix = self.assign_criterion_wh(gt_wh, anchor, self.anchor_match_threshold)\n",
    "                elif self.assign_method == 'iou':\n",
    "                    assert self.anchor_match_threshold < 1, 'threshold is totally different for wh and iou assign'\n",
    "                    matched_matrix = self.assign_criterion_iou(gt_wh, anchor, self.anchor_match_threshold)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "\n",
    "                n_gt = tf.shape(gt_wh)[0]\n",
    "                assigned_anchor = tf.tile(tf.reshape(tf.range(self.n_anchor_per_scale), (self.n_anchor_per_scale, 1)),(1, n_gt))\n",
    "\n",
    "                assigned_anchor = tf.expand_dims(assigned_anchor[matched_matrix], 1)  # filter\n",
    "                assigned_anchor = tf.cast(assigned_anchor, tf.int32)\n",
    "\n",
    "                assigned_label = tf.tile(tf.expand_dims(scaled_labels, 0), [self.n_anchor_per_scale, 1, 1])\n",
    "                assigned_label = assigned_label[matched_matrix]\n",
    "\n",
    "                if self.extend_offset:\n",
    "                    assigned_label, assigned_anchor, grid_offset = self.enrich_pos_by_position(\n",
    "                        assigned_label, assigned_anchor, gain, matched_matrix)\n",
    "                else:\n",
    "                    grid_offset = tf.zeros_like(assigned_label[:, 0:2])\n",
    "\n",
    "                assigned_grid = tf.cast(assigned_label[..., 0:2] - grid_offset, tf.int32)  # n_matched * 2\n",
    "                assigned_grid = tf.clip_by_value(assigned_grid, clip_value_min=0, clip_value_max=grid_size-1)\n",
    "                \n",
    "                # tensor: grid * grid * 3 * 6, indices（sparse index）: ~n_gt * gr * gr * 3, updates: ~n_gt * 6\n",
    "                assigned_indices = tf.concat([assigned_grid[:, 1:2], assigned_grid[:, 0:1], assigned_anchor],\n",
    "                                             axis=1)\n",
    "\n",
    "                xy, wh, clss = tf.split(assigned_label, (2, 2, 1), axis=-1)\n",
    "                xy = xy / gain[0] * self.img_size\n",
    "                wh = wh / gain[1] * self.img_size\n",
    "                obj = tf.ones_like(clss)\n",
    "                assigned_updates = tf.concat([xy, wh, obj, clss], axis=-1)\n",
    "        \n",
    "                y_true = tf.tensor_scatter_nd_update(y_true, assigned_indices, assigned_updates)\n",
    "            y_anchor_encode.append(y_true)\n",
    "        \n",
    "        return tuple(y_anchor_encode)  # add a tuple is important here, otherwise raise an error\n",
    "\n",
    "    def assign_criterion_wh(self, gt_wh, anchors, anchor_threshold):\n",
    "        # return: please note that the v5 default anchor_threshold is 4.0, related to the positive sample augment\n",
    "        gt_wh = tf.expand_dims(gt_wh, 0)  # => 1 * n_gt * 2\n",
    "        anchors = tf.expand_dims(anchors, 1)  # => n_anchor * 1 * 2\n",
    "        ratio = gt_wh / anchors  # => n_anchor * n_gt * 2\n",
    "        matched_matrix = tf.reduce_max(tf.math.maximum(ratio, 1 / ratio),\n",
    "                                       axis=2) < anchor_threshold  # => n_anchor * n_gt\n",
    "        return matched_matrix\n",
    "\n",
    "    def assign_criterion_iou(self, gt_wh, anchors, anchor_threshold):\n",
    "        # by IOU, anchor_threshold < 1\n",
    "        box_wh = tf.expand_dims(gt_wh, 0)  # => 1 * n_gt * 2\n",
    "        box_area = box_wh[..., 0] * box_wh[..., 1]  # => 1 * n_gt\n",
    "\n",
    "        anchors = tf.cast(anchors, tf.float32)  # => n_anchor * 2\n",
    "        anchors = tf.expand_dims(anchors, 1)  # => n_anchor * 1 * 2\n",
    "        anchors_area = anchors[..., 0] * anchors[..., 1]  # => n_anchor * 1\n",
    "\n",
    "        inter = tf.math.minimum(anchors[..., 0], box_wh[..., 0]) * tf.math.minimum(anchors[..., 1],\n",
    "                                                                                   box_wh[..., 1])  # n_gt * n_anchor\n",
    "        iou = inter / (anchors_area + box_area - inter + 1e-9)\n",
    "\n",
    "        iou = iou > anchor_threshold\n",
    "        return iou\n",
    "\n",
    "    def enrich_pos_by_position(self, assigned_label, assigned_anchor, gain, matched_matrix, rect_style='rect4'):\n",
    "        # using offset to extend more postive result, if x\n",
    "        assigned_xy = assigned_label[..., 0:2]  # n_matched * 2\n",
    "        offset = tf.constant([[0, 0], [1, 0], [0, 1], [-1, 0], [0, -1]], tf.float32)\n",
    "        grid_offset = tf.zeros_like(assigned_xy)\n",
    "\n",
    "        if rect_style == 'rect2':\n",
    "            g = 0.2  # offset\n",
    "        elif rect_style == 'rect4':\n",
    "            g = 0.5  # offset\n",
    "            matched = (assigned_xy % 1. < g) & (assigned_xy > 1.)\n",
    "            matched_left = matched[:, 0]\n",
    "            matched_up = matched[:, 1]\n",
    "            matched = (assigned_xy % 1. > (1 - g)) & (assigned_xy < tf.expand_dims(gain[0:2], 0) - 1.)\n",
    "            matched_right = matched[:, 0]\n",
    "            matched_down = matched[:, 1]\n",
    "\n",
    "            assigned_anchor = tf.concat([assigned_anchor, assigned_anchor[matched_left], assigned_anchor[matched_up],\n",
    "                                         assigned_anchor[matched_right], assigned_anchor[matched_down]], axis=0)\n",
    "            assigned_label = tf.concat([assigned_label, assigned_label[matched_left], assigned_label[matched_up],\n",
    "                                        assigned_label[matched_right], assigned_label[matched_down]], axis=0)\n",
    "\n",
    "            grid_offset = g * tf.concat(\n",
    "                [grid_offset, grid_offset[matched_left] + offset[1], grid_offset[matched_up] + offset[2],\n",
    "                 grid_offset[matched_right] + offset[3], grid_offset[matched_down] + offset[4]], axis=0)\n",
    "\n",
    "        return assigned_label, assigned_anchor, grid_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = np.array([[[10,13], [16,30], [33,23]],       # P3/8\n",
    "           [[30,61], [62,45], [59,119]],      # P4/16\n",
    "           [[116,90], [156,198], [373,326]]], dtype=np.float32)  # P5/32\n",
    "grids = np.array([8, 16, 32])\n",
    "img_size = np.array(640)\n",
    "anchor_assign_method = \"wh\"\n",
    "anchor_positive_augment = True\n",
    "anchorlabeler = AnchorLabeler(anchors, grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"/app/data/images/small_set/\"\n",
    "label_dir = \"/app/data/labels/small_set/\"\n",
    "yolo_reader = YOLODataReader(img_dir, label_dir)\n",
    "data_loader = DataLoader(yolo_reader,\n",
    "                         anchors,\n",
    "                         grids,\n",
    "                         img_size,\n",
    "                         anchor_assign_method,\n",
    "                         anchor_positive_augment)\n",
    "train_dataset = data_loader(batch_size=1, anchor_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 640, 640, 3)\n",
      "(1, 80, 80, 3, 6)\n",
      "(1, 40, 40, 3, 6)\n",
      "(1, 20, 20, 3, 6)\n",
      "(1, 640, 640, 3)\n",
      "(1, 80, 80, 3, 6)\n",
      "(1, 40, 40, 3, 6)\n",
      "(1, 20, 20, 3, 6)\n",
      "(1, 640, 640, 3)\n",
      "(1, 80, 80, 3, 6)\n",
      "(1, 40, 40, 3, 6)\n",
      "(1, 20, 20, 3, 6)\n",
      "(1, 640, 640, 3)\n",
      "(1, 80, 80, 3, 6)\n",
      "(1, 40, 40, 3, 6)\n",
      "(1, 20, 20, 3, 6)\n",
      "(1, 640, 640, 3)\n",
      "(1, 80, 80, 3, 6)\n",
      "(1, 40, 40, 3, 6)\n",
      "(1, 20, 20, 3, 6)\n",
      "(1, 640, 640, 3)\n",
      "(1, 80, 80, 3, 6)\n",
      "(1, 40, 40, 3, 6)\n",
      "(1, 20, 20, 3, 6)\n",
      "(1, 640, 640, 3)\n",
      "(1, 80, 80, 3, 6)\n",
      "(1, 40, 40, 3, 6)\n",
      "(1, 20, 20, 3, 6)\n",
      "(1, 640, 640, 3)\n",
      "(1, 80, 80, 3, 6)\n",
      "(1, 40, 40, 3, 6)\n",
      "(1, 20, 20, 3, 6)\n",
      "(1, 640, 640, 3)\n",
      "(1, 80, 80, 3, 6)\n",
      "(1, 40, 40, 3, 6)\n",
      "(1, 20, 20, 3, 6)\n",
      "(1, 640, 640, 3)\n",
      "(1, 80, 80, 3, 6)\n",
      "(1, 40, 40, 3, 6)\n",
      "(1, 20, 20, 3, 6)\n",
      "(1, 640, 640, 3)\n",
      "(1, 80, 80, 3, 6)\n",
      "(1, 40, 40, 3, 6)\n",
      "(1, 20, 20, 3, 6)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset:\n",
    "    print(x.shape)\n",
    "    print(y[0].shape)\n",
    "    print(y[1].shape)    \n",
    "    print(y[2].shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
